{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bf1577c-6f3b-4b1c-a848-8f5e45ff8111",
   "metadata": {},
   "source": [
    "# Sequence modeling for ranking task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9309e017-0449-46ee-b7ca-4c4bcadeedf6",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8f6e8d-f776-4d39-898c-d783c5ae3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35b3499d-dc9c-405a-8714-a26341b581e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/mlflow/pyfunc/utils/data_validation.py:168: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from loguru import logger\n",
    "from mlflow.exceptions import MlflowException\n",
    "from mlflow.models.signature import infer_signature\n",
    "from pydantic import BaseModel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import mlflow\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.dataset import UserItemRatingDFDataset\n",
    "from src.eval.compare_runs import ModelMetricsComparisonVisualizer\n",
    "from src.id_mapper import IDMapper\n",
    "from src.sequence.inference import SequenceRatingPredictionInferenceWrapper\n",
    "from src.sequence.model import SequenceRatingPrediction\n",
    "from src.sequence.trainer import LitSequenceRatingPrediction\n",
    "from src.sequence.utils import generate_item_sequences\n",
    "from src.viz import custom_style_plotly\n",
    "\n",
    "load_dotenv()\n",
    "custom_style_plotly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd804021-3424-48e0-973a-e662a72db544",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce522d9e-f35c-4cc5-a71e-68447956b31f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# This is a parameter cell used by papermill\n",
    "max_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea4e9a93-5b6a-4dec-97f0-b9aa3383c64d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-08 14:42:58.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m47\u001b[0m - \u001b[1mSetting up MLflow experiment Retriever - run 001-sequence-model...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"testing\": false,\n",
      "  \"author\": \"quy.dinh\",\n",
      "  \"log_to_mlflow\": true,\n",
      "  \"experiment_name\": \"Retriever\",\n",
      "  \"run_name\": \"001-sequence-model\",\n",
      "  \"notebook_persist_dp\": \"/home/dvq/frostmourne/recsys-blog/1-seq-model/notebooks/data/001-sequence-model\",\n",
      "  \"random_seed\": 41,\n",
      "  \"device\": \"cuda\",\n",
      "  \"max_epochs\": 100,\n",
      "  \"batch_size\": 128,\n",
      "  \"user_col\": \"user_id\",\n",
      "  \"item_col\": \"parent_asin\",\n",
      "  \"rating_col\": \"rating\",\n",
      "  \"timestamp_col\": \"timestamp\",\n",
      "  \"top_K\": 100,\n",
      "  \"top_k\": 10,\n",
      "  \"embedding_dim\": 128,\n",
      "  \"dropout\": 0.3,\n",
      "  \"early_stopping_patience\": 5,\n",
      "  \"learning_rate\": 0.001,\n",
      "  \"l2_reg\": 0.00001,\n",
      "  \"mlf_item2vec_model_name\": \"item2vec\",\n",
      "  \"mlf_model_name\": \"sequence_rating_prediction\",\n",
      "  \"min_roc_auc\": 0.7,\n",
      "  \"best_checkpoint_path\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Args(BaseModel):\n",
    "    testing: bool = False\n",
    "    author: str = \"quy.dinh\"\n",
    "    log_to_mlflow: bool = True\n",
    "    experiment_name: str = \"Retriever\"\n",
    "    run_name: str = \"001-sequence-model\"\n",
    "    notebook_persist_dp: str = None\n",
    "    random_seed: int = 41\n",
    "    device: str = None\n",
    "\n",
    "    max_epochs: int = max_epochs\n",
    "    batch_size: int = 128\n",
    "\n",
    "    user_col: str = \"user_id\"\n",
    "    item_col: str = \"parent_asin\"\n",
    "    rating_col: str = \"rating\"\n",
    "    timestamp_col: str = \"timestamp\"\n",
    "\n",
    "    top_K: int = 100\n",
    "    top_k: int = 10\n",
    "\n",
    "    batch_size: int = 128\n",
    "\n",
    "    embedding_dim: int = 128\n",
    "    dropout: float = 0.3\n",
    "    early_stopping_patience: int = 5\n",
    "    learning_rate: float = 0.001\n",
    "    l2_reg: float = 1e-5\n",
    "\n",
    "    mlf_item2vec_model_name: str = \"item2vec\"\n",
    "    mlf_model_name: str = \"sequence_rating_prediction\"\n",
    "    min_roc_auc: float = 0.7\n",
    "\n",
    "    best_checkpoint_path: str = None\n",
    "\n",
    "    def init(self):\n",
    "        self.notebook_persist_dp = os.path.abspath(f\"data/{self.run_name}\")\n",
    "        os.makedirs(self.notebook_persist_dp, exist_ok=True)\n",
    "\n",
    "        if not (mlflow_uri := os.environ.get(\"MLFLOW_TRACKING_URI\")):\n",
    "            logger.warning(\n",
    "                \"Environment variable MLFLOW_TRACKING_URI is not set. Setting self.log_to_mlflow to false.\"\n",
    "            )\n",
    "            self.log_to_mlflow = False\n",
    "\n",
    "        if self.log_to_mlflow:\n",
    "            logger.info(\n",
    "                f\"Setting up MLflow experiment {self.experiment_name} - run {self.run_name}...\"\n",
    "            )\n",
    "            self._mlf_logger = MLFlowLogger(\n",
    "                experiment_name=self.experiment_name,\n",
    "                run_name=self.run_name,\n",
    "                tracking_uri=mlflow_uri,\n",
    "                log_model=True,\n",
    "            )\n",
    "\n",
    "        if self.device is None:\n",
    "            self.device = (\n",
    "                \"cuda\"\n",
    "                if torch.cuda.is_available()\n",
    "                else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "            )\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "args = Args().init()\n",
    "\n",
    "print(args.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acedcb-89e6-41c6-8969-bf3437fc7898",
   "metadata": {},
   "source": [
    "# Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a34cb5b-c7db-4b95-952b-5f4cb2e1a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(n_users, n_items, embedding_dim, dropout, item_embedding=None):\n",
    "    model = SequenceRatingPrediction(\n",
    "        n_users, n_items, embedding_dim, dropout=dropout, item_embedding=item_embedding\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a71da-1ee3-474c-b3f4-4488d2a45dd3",
   "metadata": {},
   "source": [
    "# Test implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5326d7-ec9d-422c-bbd8-03c837a23e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 8\n",
    "batch_size = 2\n",
    "\n",
    "# Mock data\n",
    "user_indices = [0, 0, 1, 2, 2]\n",
    "item_indices = [0, 1, 2, 3, 4]\n",
    "timestamps = [0, 1, 2, 3, 4]\n",
    "ratings = [0, 4, 5, 3, 0]\n",
    "item_sequences = [\n",
    "    [-1, -1, 2, 3],\n",
    "    [-1, -1, 2, 3],\n",
    "    [-1, -1, 1, 3],\n",
    "    [-1, -1, 2, 1],\n",
    "    [-1, -1, 2, 1],\n",
    "]\n",
    "\n",
    "n_users = len(set(user_indices))\n",
    "n_items = len(set(item_indices))\n",
    "\n",
    "train_df = pd.DataFrame(\n",
    "    {\n",
    "        \"user_indice\": user_indices,\n",
    "        \"item_indice\": item_indices,\n",
    "        args.timestamp_col: timestamps,\n",
    "        args.rating_col: ratings,\n",
    "        \"item_sequence\": item_sequences,\n",
    "    }\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, embedding_dim, args.dropout)\n",
    "\n",
    "# Example forward pass\n",
    "model.eval()\n",
    "user = torch.tensor([0])\n",
    "item_sequence = torch.tensor([[-1, -1, -1, 0, 1]])\n",
    "target_item = torch.tensor([2])\n",
    "predictions = model.predict(user, item_sequence, target_item)\n",
    "print(predictions)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0b1fea-0376-4624-ad8a-d000208a97f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rating_dataset = UserItemRatingDFDataset(\n",
    "    train_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=batch_size, shuffle=False, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e82d3d1-826a-409b-8440-46e0bd924269",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_input in train_loader:\n",
    "    print(batch_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cb9ca4-11f1-45a8-911b-ed11c8391944",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model\n",
    "lit_model = LitSequenceRatingPrediction(model, log_dir=args.notebook_persist_dp)\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=f\"{args.notebook_persist_dp}/test\",\n",
    "    max_epochs=2,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model, train_dataloaders=train_loader, val_dataloaders=train_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf019c8-db28-4538-91e8-3904b8800e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = torch.tensor([0, 0, 0, 0])\n",
    "item_sequences = torch.tensor(\n",
    "    [[-1, -1, 2, 3], [-1, -1, 2, 3], [-1, -1, 1, 3], [-1, -1, 2, 1]]\n",
    ")\n",
    "items = torch.tensor([0, 1, 2, 3])\n",
    "predictions = model.predict(users, item_sequences, items)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f02734-1e63-4201-bd34-b3938ae50fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predict_df(\n",
    "    train_df,\n",
    "    val_user_indices,\n",
    "    val_timestamp,\n",
    "    rating_col,\n",
    "    timestamp_col,\n",
    "    sequence_length=10,\n",
    "):\n",
    "    predict_df = pd.DataFrame(\n",
    "        {\n",
    "            \"user_indice\": val_user_indices,\n",
    "            \"item_indice\": -1,  # placeholder\n",
    "            \"timestamp\": val_timestamp,\n",
    "            \"source\": \"predict\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    predict_df = (\n",
    "        pd.concat(\n",
    "            [\n",
    "                train_df.loc[lambda df: df[rating_col].gt(0)][\n",
    "                    [\"user_indice\", \"item_indice\", timestamp_col]\n",
    "                ].assign(source=\"train\"),\n",
    "                predict_df,\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "        .pipe(\n",
    "            generate_item_sequences,\n",
    "            \"user_indice\",\n",
    "            \"item_indice\",\n",
    "            timestamp_col,\n",
    "            sequence_length=sequence_length,\n",
    "            padding=True,\n",
    "            padding_value=-1,\n",
    "        )\n",
    "        .loc[lambda df: df[\"source\"].eq(\"predict\")]\n",
    "        .assign(item_sequence=lambda df: df[\"item_sequence\"].apply(np.array))\n",
    "    )\n",
    "\n",
    "    return predict_df\n",
    "\n",
    "\n",
    "predict_df = create_predict_df(\n",
    "    train_df,\n",
    "    user_indices,\n",
    "    timestamps[-1],\n",
    "    args.rating_col,\n",
    "    args.timestamp_col,\n",
    "    sequence_length=10,\n",
    ")\n",
    "\n",
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fdcf97-6271-406d-81b5-7e91a4c42dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = model.recommend(\n",
    "    torch.tensor(predict_df[\"user_indice\"].values),\n",
    "    torch.tensor(predict_df[\"item_sequence\"].values.tolist()),\n",
    "    k=2,\n",
    "    batch_size=4,\n",
    ")\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170dec89-a874-4dce-8f94-07d978fcc5b8",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83803362-5eaa-40bb-b28b-878316d5db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"../data/train_features_neg_df.parquet\")\n",
    "val_df = pd.read_parquet(\"../data/val_features_neg_df.parquet\")\n",
    "idm_fp = \"../data/idm.json\"\n",
    "idm = IDMapper().load(idm_fp)\n",
    "\n",
    "assert (\n",
    "    train_df[args.user_col].map(lambda s: idm.get_user_index(s))\n",
    "    != train_df[\"user_indice\"]\n",
    ").sum() == 0, \"Mismatch IDM\"\n",
    "assert (\n",
    "    val_df[args.user_col].map(lambda s: idm.get_user_index(s)) != val_df[\"user_indice\"]\n",
    ").sum() == 0, \"Mismatch IDM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f1e6e9-48ba-4f48-b693-ac028845938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_indices = train_df[\"user_indice\"].unique()\n",
    "item_indices = train_df[\"item_indice\"].unique()\n",
    "\n",
    "logger.info(f\"{len(user_indices)=:,.0f}, {len(item_indices)=:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92a8ea7-928c-4656-b92c-2e137d78404a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260fbe7-2f90-44a1-be74-ce5db9b511ee",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240a04ed-8898-443f-b0f4-7399bfa63810",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset = UserItemRatingDFDataset(\n",
    "    train_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col\n",
    ")\n",
    "val_rating_dataset = UserItemRatingDFDataset(\n",
    "    val_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_rating_dataset, batch_size=args.batch_size, shuffle=False, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dcf157-425f-4d15-9b53-e1ff93887def",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_items = len(item_indices)\n",
    "n_users = len(user_indices)\n",
    "\n",
    "model = init_model(n_users, n_items, args.embedding_dim, args.dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cbb2a8-a578-4ad2-941e-efd01d930336",
   "metadata": {},
   "source": [
    "#### Predict before train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d95ffc-0aec-4239-aa33-d75dc2f40b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.item_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0112de1e-1dce-4982-9663-a1df91fd0001",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_df = val_rating_dataset.df\n",
    "val_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb1583b-40f7-4157-a383-5891389ac119",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_id = val_df.sample(1)[args.user_col].values[0]\n",
    "# user_id = \"AH4AOFTTDPHPAFAAVFMAF25H2LIQ\"\n",
    "test_df = val_df.loc[lambda df: df[args.user_col].eq(user_id)]\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48fbc80-eda8-4dff-a246-95f8f2f75082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_row = test_df.loc[lambda df: df[args.rating_col].gt(0)].iloc[0]\n",
    "item_id = test_row[args.item_col]\n",
    "item_sequence = test_row[\"item_sequence\"]\n",
    "logger.info(\n",
    "    f\"Test predicting before training with {args.user_col} = {user_id} and {args.item_col} = {item_id}\"\n",
    ")\n",
    "user_indice = idm.get_user_index(user_id)\n",
    "item_indice = idm.get_item_index(item_id)\n",
    "user = torch.tensor([user_indice])\n",
    "item_sequence = torch.tensor([item_sequence])\n",
    "item = torch.tensor([item_indice])\n",
    "\n",
    "model.eval()\n",
    "model.predict(user, item_sequence, item)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fd217c-c0c8-4e7c-81fe-6eb36f4729b5",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9daad4-1365-4e8e-8f73-80ca5513572b",
   "metadata": {},
   "source": [
    "##### Overfit 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1cd9bd-e2c6-404b-b6ae-b26a7d35a0ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_roc_auc\", patience=10, mode=\"max\", verbose=False\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, args.embedding_dim, dropout=0)\n",
    "lit_model = LitSequenceRatingPrediction(\n",
    "    model,\n",
    "    learning_rate=args.learning_rate,\n",
    "    l2_reg=0.0,\n",
    "    log_dir=args.notebook_persist_dp,\n",
    "    accelerator=args.device,\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persist_dp}/logs/overfit\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    max_epochs=100,\n",
    "    overfit_batches=1,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=train_loader,\n",
    ")\n",
    "logger.info(f\"Logs available at {trainer.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cc9ae0-a993-4815-bebd-85cc51e68e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to make sure port 6006 at local is accessible\n",
    "%tensorboard --logdir $trainer.log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c7e4af-5c66-454e-9e2c-2ca134f4e1cf",
   "metadata": {},
   "source": [
    "##### Fit on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef36c3-5263-4d91-8d7f-364d45c20719",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# papermill_description=fit-model\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_roc_auc\", patience=args.early_stopping_patience, mode=\"max\", verbose=False\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{args.notebook_persist_dp}/checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_roc_auc\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "model = init_model(\n",
    "    n_users,\n",
    "    n_items,\n",
    "    args.embedding_dim,\n",
    "    dropout=args.dropout\n",
    ")\n",
    "lit_model = LitSequenceRatingPrediction(\n",
    "    model,\n",
    "    learning_rate=args.learning_rate,\n",
    "    l2_reg=args.l2_reg,\n",
    "    log_dir=args.notebook_persist_dp,\n",
    "    evaluate_ranking=True,\n",
    "    idm=idm,\n",
    "    args=args,\n",
    "    accelerator=args.device,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persist_dp}/logs/run\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    max_epochs=args.max_epochs,\n",
    "    callbacks=[early_stopping, checkpoint_callback],\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    logger=args._mlf_logger if args.log_to_mlflow else None,\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af44bf35-e7c7-4718-97b8-238e89b7f3f0",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.info(\n",
    "    f\"Test predicting after training with {args.user_col} = {user_id} and {args.item_col} = {item_id}\"\n",
    ")\n",
    "model.eval()\n",
    "model = model.to(user.device)\n",
    "model.predict(user, item_sequence, item)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e1dd22-bcb9-4582-96d0-30acc4e8b790",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Load best checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092427a8-ac4e-4752-a0ee-10729b6e563c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.info(f\"Loading best checkpoint from {checkpoint_callback.best_model_path}...\")\n",
    "args.best_checkpoint_path = checkpoint_callback.best_model_path\n",
    "\n",
    "best_trainer = LitSequenceRatingPrediction.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    model=init_model(n_users, n_items, args.embedding_dim, dropout=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68989e7-cd28-4cb3-9a28-5bd477bb67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = best_trainer.model.to(lit_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72062d94-6ee8-480f-b7c6-9dcae2ceeb8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "best_model.predict(user, item_sequence, item)\n",
    "best_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26afc39d-5cbd-4ea4-9484-f6419b460bde",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Persist id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275bcb81-bf50-4757-9e63-5c7a317b276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.log_to_mlflow:\n",
    "    # Persist id_mapping so that at inference we can predict based on item_ids (string) instead of item_index\n",
    "    run_id = trainer.logger.run_id\n",
    "    mlf_client = trainer.logger.experiment\n",
    "    mlf_client.log_artifact(run_id, idm_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a53735-cada-4b16-b6ec-b958e20d8093",
   "metadata": {},
   "source": [
    "### Wrap inference function and register best checkpoint as MLflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1da4ca-1616-4f57-99fb-cb851c535a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferrer = SequenceRatingPredictionInferenceWrapper(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21791a9-d5fc-4abe-bc3c-820aba9f0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = {\n",
    "    \"user_ids\": [idm.get_user_id(0)],\n",
    "    \"item_sequences\": [[idm.get_item_id(0), idm.get_item_id(1)]],\n",
    "    \"item_ids\": [idm.get_item_id(0)],\n",
    "}\n",
    "sample_output = inferrer.infer([0], [[0, 1]], [0])\n",
    "sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c043a-f777-4ade-ab80-cfa4d90aafa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args.log_to_mlflow:\n",
    "    run_id = trainer.logger.run_id\n",
    "    sample_output_np = sample_output\n",
    "    signature = infer_signature(sample_input, sample_output_np)\n",
    "    idm_filename = idm_fp.split(\"/\")[-1]\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        mlflow.pyfunc.log_model(\n",
    "            python_model=inferrer,\n",
    "            artifact_path=\"inferrer\",\n",
    "            # We log the id_mapping to the predict function so that it can accept item_id and automatically convert ot item_indice for PyTorch model to use\n",
    "            artifacts={\"idm\": mlflow.get_artifact_uri(idm_filename)},\n",
    "            signature=signature,\n",
    "            input_example=sample_input,\n",
    "            registered_model_name=args.mlf_model_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d5150-9851-4e61-b1af-8e619abc9ea4",
   "metadata": {},
   "source": [
    "# Set the newly trained model as champion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf6428a-bc47-400a-99ac-666abfa4ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.log_to_mlflow:\n",
    "    # Get current champion\n",
    "    deploy_alias = \"champion\"\n",
    "    curr_model_run_id = None\n",
    "\n",
    "    min_roc_auc = args.min_roc_auc\n",
    "\n",
    "    try:\n",
    "        curr_champion_model = mlf_client.get_model_version_by_alias(\n",
    "            args.mlf_model_name, deploy_alias\n",
    "        )\n",
    "        curr_model_run_id = curr_champion_model.run_id\n",
    "    except MlflowException as e:\n",
    "        if \"not found\" in str(e).lower():\n",
    "            logger.info(\n",
    "                f\"There is no {deploy_alias} alias for model {args.mlf_model_name}\"\n",
    "            )\n",
    "\n",
    "    # Compare new vs curr models\n",
    "    new_mlf_run = trainer.logger.experiment.get_run(trainer.logger.run_id)\n",
    "    new_metrics = new_mlf_run.data.metrics\n",
    "    roc_auc = new_metrics[\"roc_auc\"]\n",
    "    if curr_model_run_id:\n",
    "        curr_model_run_info = mlf_client.get_run(curr_model_run_id)\n",
    "        curr_metrics = curr_model_run_info.data.metrics\n",
    "        if (curr_roc_auc := curr_metrics[\"roc_auc\"]) > min_roc_auc:\n",
    "            logger.info(\n",
    "                f\"Current {deploy_alias} model has {curr_roc_auc:,.4f} ROC-AUC. Setting it to the deploy baseline...\"\n",
    "            )\n",
    "            min_roc_auc = curr_roc_auc\n",
    "\n",
    "        top_metrics = [\"roc_auc\"]\n",
    "        vizer = ModelMetricsComparisonVisualizer(curr_metrics, new_metrics, top_metrics)\n",
    "        print(\"Comparing metrics between new run and current champion:\")\n",
    "        display(vizer.compare_metrics_df())\n",
    "        vizer.create_metrics_comparison_plot(n_cols=5)\n",
    "        vizer.plot_diff()\n",
    "\n",
    "    # Register new champion\n",
    "    if roc_auc < min_roc_auc:\n",
    "        logger.info(\n",
    "            f\"Current run has ROC-AUC = {roc_auc:,.4f}, smaller than {min_roc_auc:,.4f}. Skip aliasing this model as the new {deploy_alias}..\"\n",
    "        )\n",
    "    else:\n",
    "        logger.info(\"Aliasing the new model as champion...\")\n",
    "        # Get the model version for current run by assuming it's the most recent registered version\n",
    "        model_version = (\n",
    "            mlf_client.get_registered_model(args.mlf_model_name)\n",
    "            .latest_versions[0]\n",
    "            .version\n",
    "        )\n",
    "\n",
    "        mlf_client.set_registered_model_alias(\n",
    "            name=args.mlf_model_name, alias=\"champion\", version=model_version\n",
    "        )\n",
    "\n",
    "        mlf_client.set_model_version_tag(\n",
    "            name=args.mlf_model_name,\n",
    "            version=model_version,\n",
    "            key=\"author\",\n",
    "            value=args.author,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32096360-c26a-42de-9564-30634fb76eeb",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c6850-e4de-43fa-b132-0b97f138a0ed",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_params = [args]\n",
    "\n",
    "if args.log_to_mlflow:\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        for params in all_params:\n",
    "            params_dict = params.dict()\n",
    "            params_ = dict()\n",
    "            for k, v in params_dict.items():\n",
    "                if k == \"top_K\":\n",
    "                    k = \"top_big_K\"\n",
    "                if k == \"top_k\":\n",
    "                    k = \"top_small_k\"\n",
    "                params_[f\"{params.__repr_name__()}.{k}\"] = v\n",
    "            mlflow.log_params(params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cff81a-484e-4919-be8f-0351cce91a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
