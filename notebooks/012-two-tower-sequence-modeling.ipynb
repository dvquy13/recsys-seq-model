{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bf1577c-6f3b-4b1c-a848-8f5e45ff8111",
   "metadata": {},
   "source": [
    "# Sequence modeling for ranking task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9309e017-0449-46ee-b7ca-4c4bcadeedf6",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8f6e8d-f776-4d39-898c-d783c5ae3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35b3499d-dc9c-405a-8714-a26341b581e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/mlflow/pyfunc/utils/data_validation.py:168: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from loguru import logger\n",
    "from mlflow.exceptions import MlflowException\n",
    "from mlflow.models.signature import infer_signature\n",
    "from pydantic import BaseModel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import mlflow\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.dataset import UserItemBinaryDFDataset as UserItemRatingDFDataset\n",
    "from src.id_mapper import IDMapper\n",
    "from src.sequence.inference import SequenceRatingPredictionInferenceWrapper\n",
    "from src.eval.compare_runs import ModelMetricsComparisonVisualizer\n",
    "from src.sequence.model import TwoTowerSequenceModel\n",
    "from src.sequence.trainer import LitSequenceRatingPrediction\n",
    "from src.sequence.utils import generate_item_sequences\n",
    "from src.viz import custom_style_plotly\n",
    "\n",
    "load_dotenv()\n",
    "custom_style_plotly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd804021-3424-48e0-973a-e662a72db544",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce522d9e-f35c-4cc5-a71e-68447956b31f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# This is a parameter cell used by papermill\n",
    "max_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea4e9a93-5b6a-4dec-97f0-b9aa3383c64d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-08 21:39:08.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mSetting up MLflow experiment Retrieve - Binary - run 003-two-tower-sequence-modeling...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"testing\": false,\n",
      "  \"author\": \"quy.dinh\",\n",
      "  \"log_to_mlflow\": true,\n",
      "  \"experiment_name\": \"Retrieve - Binary\",\n",
      "  \"run_name\": \"003-two-tower-sequence-modeling\",\n",
      "  \"notebook_persist_dp\": \"/home/dvq/frostmourne/recsys-blog/1-seq-model/notebooks/data/003-two-tower-sequence-modeling\",\n",
      "  \"random_seed\": 41,\n",
      "  \"device\": \"cuda\",\n",
      "  \"max_epochs\": 100,\n",
      "  \"batch_size\": 128,\n",
      "  \"user_col\": \"user_id\",\n",
      "  \"item_col\": \"parent_asin\",\n",
      "  \"rating_col\": \"rating\",\n",
      "  \"timestamp_col\": \"timestamp\",\n",
      "  \"top_k_retrieve\": 100,\n",
      "  \"top_k_rerank\": 10,\n",
      "  \"embedding_dim\": 128,\n",
      "  \"dropout\": 0.3,\n",
      "  \"early_stopping_patience\": 5,\n",
      "  \"learning_rate\": 0.001,\n",
      "  \"l2_reg\": 0.00001,\n",
      "  \"mlf_model_name\": \"two_tower_sequence\",\n",
      "  \"min_roc_auc\": 0.7,\n",
      "  \"best_checkpoint_path\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Args(BaseModel):\n",
    "    testing: bool = False\n",
    "    author: str = \"quy.dinh\"\n",
    "    log_to_mlflow: bool = True\n",
    "    experiment_name: str = \"Retrieve - Binary\"\n",
    "    run_name: str = \"003-two-tower-sequence-modeling\"\n",
    "    notebook_persist_dp: str = None\n",
    "    random_seed: int = 41\n",
    "    device: str = None\n",
    "\n",
    "    max_epochs: int = max_epochs\n",
    "    batch_size: int = 128\n",
    "\n",
    "    user_col: str = \"user_id\"\n",
    "    item_col: str = \"parent_asin\"\n",
    "    rating_col: str = \"rating\"\n",
    "    timestamp_col: str = \"timestamp\"\n",
    "\n",
    "    top_k_retrieve: int = 100\n",
    "    top_k_rerank: int = 10\n",
    "\n",
    "    batch_size: int = 128\n",
    "\n",
    "    embedding_dim: int = 128\n",
    "    dropout: float = 0.3\n",
    "    early_stopping_patience: int = 5\n",
    "    learning_rate: float = 0.001\n",
    "    l2_reg: float = 1e-5\n",
    "\n",
    "    mlf_model_name: str = \"two_tower_sequence\"\n",
    "    min_roc_auc: float = 0.7\n",
    "\n",
    "    best_checkpoint_path: str = None\n",
    "\n",
    "    def init(self):\n",
    "        self.notebook_persist_dp = os.path.abspath(f\"data/{self.run_name}\")\n",
    "        os.makedirs(self.notebook_persist_dp, exist_ok=True)\n",
    "\n",
    "        if not (mlflow_uri := os.environ.get(\"MLFLOW_TRACKING_URI\")):\n",
    "            logger.warning(\n",
    "                \"Environment variable MLFLOW_TRACKING_URI is not set. Setting self.log_to_mlflow to false.\"\n",
    "            )\n",
    "            self.log_to_mlflow = False\n",
    "\n",
    "        if self.log_to_mlflow:\n",
    "            logger.info(\n",
    "                f\"Setting up MLflow experiment {self.experiment_name} - run {self.run_name}...\"\n",
    "            )\n",
    "            self._mlf_logger = MLFlowLogger(\n",
    "                experiment_name=self.experiment_name,\n",
    "                run_name=self.run_name,\n",
    "                tracking_uri=mlflow_uri,\n",
    "                log_model=True,\n",
    "            )\n",
    "\n",
    "        if self.device is None:\n",
    "            self.device = (\n",
    "                \"cuda\"\n",
    "                if torch.cuda.is_available()\n",
    "                else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "            )\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "args = Args().init()\n",
    "\n",
    "print(args.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acedcb-89e6-41c6-8969-bf3437fc7898",
   "metadata": {},
   "source": [
    "# Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a34cb5b-c7db-4b95-952b-5f4cb2e1a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(n_users, n_items, embedding_dim, dropout):\n",
    "    model = TwoTowerSequenceModel(\n",
    "        n_users, n_items, embedding_dim, dropout=dropout\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a71da-1ee3-474c-b3f4-4488d2a45dd3",
   "metadata": {},
   "source": [
    "# Test implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce5326d7-ec9d-422c-bbd8-03c837a23e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8122], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TwoTowerSequenceModel(\n",
       "  (item_embedding): Embedding(6, 8, padding_idx=5)\n",
       "  (user_embedding): Embedding(3, 8)\n",
       "  (query_fc): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (candidate_fc): Sequential(\n",
       "    (0): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 8\n",
    "batch_size = 2\n",
    "\n",
    "# Mock data\n",
    "user_indices = [0, 0, 1, 2, 2]\n",
    "item_indices = [0, 1, 2, 3, 4]\n",
    "timestamps = [0, 1, 2, 3, 4]\n",
    "ratings = [0, 4, 5, 3, 0]\n",
    "item_sequences = [\n",
    "    [-1, -1, 2, 3],\n",
    "    [-1, -1, 2, 3],\n",
    "    [-1, -1, 1, 3],\n",
    "    [-1, -1, 2, 1],\n",
    "    [-1, -1, 2, 1],\n",
    "]\n",
    "\n",
    "n_users = len(set(user_indices))\n",
    "n_items = len(set(item_indices))\n",
    "\n",
    "train_df = pd.DataFrame(\n",
    "    {\n",
    "        \"user_indice\": user_indices,\n",
    "        \"item_indice\": item_indices,\n",
    "        args.timestamp_col: timestamps,\n",
    "        args.rating_col: ratings,\n",
    "        \"item_sequence\": item_sequences,\n",
    "    }\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, embedding_dim, args.dropout)\n",
    "\n",
    "# Example forward pass\n",
    "model.eval()\n",
    "user = torch.tensor([0])\n",
    "item_sequence = torch.tensor([[-1, -1, -1, 0, 1]])\n",
    "target_item = torch.tensor([2])\n",
    "predictions = model.predict(user, item_sequence, target_item)\n",
    "print(predictions)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c0b1fea-0376-4624-ad8a-d000208a97f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rating_dataset = UserItemRatingDFDataset(\n",
    "    train_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=batch_size, shuffle=False, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e82d3d1-826a-409b-8440-46e0bd924269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': tensor([0, 0]), 'item': tensor([0, 1]), 'rating': tensor([0., 1.]), 'item_sequence': tensor([[-1, -1,  2,  3],\n",
      "        [-1, -1,  2,  3]]), 'item_sequence_ts_bucket': tensor([], size=(2, 0), dtype=torch.int64), 'item_feature': tensor([], size=(2, 0))}\n",
      "{'user': tensor([1, 2]), 'item': tensor([2, 3]), 'rating': tensor([1., 1.]), 'item_sequence': tensor([[-1, -1,  1,  3],\n",
      "        [-1, -1,  2,  1]]), 'item_sequence_ts_bucket': tensor([], size=(2, 0), dtype=torch.int64), 'item_feature': tensor([], size=(2, 0))}\n"
     ]
    }
   ],
   "source": [
    "for batch_input in train_loader:\n",
    "    print(batch_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02cb9ca4-11f1-45a8-911b-ed11c8391944",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 SUPER') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type                   | Params | Mode \n",
      "----------------------------------------------------------------------\n",
      "0 | model              | TwoTowerSequenceModel  | 312    | train\n",
      "1 | val_roc_auc_metric | BinaryAUROC            | 0      | train\n",
      "2 | val_pr_auc_metric  | BinaryAveragePrecision | 0      | train\n",
      "----------------------------------------------------------------------\n",
      "312       Trainable params\n",
      "0         Non-trainable params\n",
      "312       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19a0ee71436456f98b598cad7f5c9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                          | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea48fc952c447df9277b2603a7fdd42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                 | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be475b34c3e4673ae5749d405d812d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141e325ea4a7470a99bbe5d15d1b5182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "\u001b[32m2025-03-08 21:39:09.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.sequence.trainer\u001b[0m:\u001b[36mon_fit_end\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mLogging classification metrics...\u001b[0m\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "lit_model = LitSequenceRatingPrediction(model, log_dir=args.notebook_persist_dp)\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=f\"{args.notebook_persist_dp}/test\",\n",
    "    max_epochs=2,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model, train_dataloaders=train_loader, val_dataloaders=train_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abf019c8-db28-4538-91e8-3904b8800e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7589, 0.7723, 0.8796, 0.6960], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "users = torch.tensor([0, 0, 0, 0])\n",
    "item_sequences = torch.tensor(\n",
    "    [[-1, -1, 2, 3], [-1, -1, 2, 3], [-1, -1, 1, 3], [-1, -1, 2, 1]]\n",
    ")\n",
    "items = torch.tensor([0, 1, 2, 3])\n",
    "predictions = model.predict(users, item_sequences, items)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f02734-1e63-4201-bd34-b3938ae50fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>predict</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>predict</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>predict</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>predict</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>predict</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_indice  item_indice  timestamp   source  \\\n",
       "0            0           -1          4  predict   \n",
       "1            0           -1          4  predict   \n",
       "2            1           -1          4  predict   \n",
       "3            2           -1          4  predict   \n",
       "4            2           -1          4  predict   \n",
       "\n",
       "                             item_sequence  \n",
       "0  [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1]  \n",
       "1  [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1]  \n",
       "2  [-1, -1, -1, -1, -1, -1, -1, -1, -1, 2]  \n",
       "3  [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3]  \n",
       "4  [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_predict_df(\n",
    "    train_df,\n",
    "    val_user_indices,\n",
    "    val_timestamp,\n",
    "    rating_col,\n",
    "    timestamp_col,\n",
    "    sequence_length=10,\n",
    "):\n",
    "    predict_df = pd.DataFrame(\n",
    "        {\n",
    "            \"user_indice\": val_user_indices,\n",
    "            \"item_indice\": -1,  # placeholder\n",
    "            \"timestamp\": val_timestamp,\n",
    "            \"source\": \"predict\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    predict_df = (\n",
    "        pd.concat(\n",
    "            [\n",
    "                train_df.loc[lambda df: df[rating_col].gt(0)][\n",
    "                    [\"user_indice\", \"item_indice\", timestamp_col]\n",
    "                ].assign(source=\"train\"),\n",
    "                predict_df,\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "        .pipe(\n",
    "            generate_item_sequences,\n",
    "            \"user_indice\",\n",
    "            \"item_indice\",\n",
    "            timestamp_col,\n",
    "            sequence_length=sequence_length,\n",
    "            padding=True,\n",
    "            padding_value=-1,\n",
    "        )\n",
    "        .loc[lambda df: df[\"source\"].eq(\"predict\")]\n",
    "        .assign(item_sequence=lambda df: df[\"item_sequence\"].apply(np.array))\n",
    "    )\n",
    "\n",
    "    return predict_df\n",
    "\n",
    "\n",
    "predict_df = create_predict_df(\n",
    "    train_df,\n",
    "    user_indices,\n",
    "    timestamps[-1],\n",
    "    args.rating_col,\n",
    "    args.timestamp_col,\n",
    "    sequence_length=10,\n",
    ")\n",
    "\n",
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50fdcf97-6271-406d-81b5-7e91a4c42dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_101924/349226613.py:3: UserWarning:\n",
      "\n",
      "Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfec8105b28445a4ac0071b5f829992d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating recommendations:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'user_indice': [0, 0, 0, 0, 1, 1, 2, 2, 2, 2],\n",
       " 'recommendation': [1, 3, 1, 3, 3, 1, 3, 1, 3, 1],\n",
       " 'score': [0.8522368669509888,\n",
       "  0.6080646514892578,\n",
       "  0.8522368669509888,\n",
       "  0.6080646514892578,\n",
       "  0.6066123247146606,\n",
       "  0.5357617735862732,\n",
       "  1.086543321609497,\n",
       "  0.3857460618019104,\n",
       "  1.0865432024002075,\n",
       "  0.385746031999588]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations = model.recommend(\n",
    "    torch.tensor(predict_df[\"user_indice\"].values),\n",
    "    torch.tensor(predict_df[\"item_sequence\"].values.tolist()),\n",
    "    k=2,\n",
    "    batch_size=4,\n",
    ")\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170dec89-a874-4dce-8f94-07d978fcc5b8",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83803362-5eaa-40bb-b28b-878316d5db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"../data/train_features_neg_df.parquet\")\n",
    "val_df = pd.read_parquet(\"../data/val_features_neg_df.parquet\")\n",
    "idm_fp = \"../data/idm.json\"\n",
    "idm = IDMapper().load(idm_fp)\n",
    "\n",
    "assert (\n",
    "    train_df[args.user_col].map(lambda s: idm.get_user_index(s))\n",
    "    != train_df[\"user_indice\"]\n",
    ").sum() == 0, \"Mismatch IDM\"\n",
    "assert (\n",
    "    val_df[args.user_col].map(lambda s: idm.get_user_index(s)) != val_df[\"user_indice\"]\n",
    ").sum() == 0, \"Mismatch IDM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86f1e6e9-48ba-4f48-b693-ac028845938f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-08 21:39:09.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mlen(user_indices)=19,734, len(item_indices)=7,388\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "user_indices = train_df[\"user_indice\"].unique()\n",
    "item_indices = train_df[\"item_indice\"].unique()\n",
    "\n",
    "logger.info(f\"{len(user_indices)=:,.0f}, {len(item_indices)=:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a92a8ea7-928c-4656-b92c-2e137d78404a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AH377TAQBGVIUD75XIOSNRRBUMSA</td>\n",
       "      <td>B000OIZSLE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1603811722410</td>\n",
       "      <td>3520</td>\n",
       "      <td>5441</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, 4238.0, 3266.0, 4316....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGPAMWVXLFFWCBO3J4JNOYBB5CJQ</td>\n",
       "      <td>B01CXE9Q8C</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1520074315327</td>\n",
       "      <td>6133</td>\n",
       "      <td>2684</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, 2863.0, 5665.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGSXDUEY3XZJVJSRBQCTAPOSY2NA</td>\n",
       "      <td>1451681755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1446855213000</td>\n",
       "      <td>15471</td>\n",
       "      <td>3848</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 2423.0, 5224.0, 6745.0, 360...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AECGNMOCHNIEKROWI6NCZQE7QV3A</td>\n",
       "      <td>B001MSMULG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1412051625000</td>\n",
       "      <td>1717</td>\n",
       "      <td>4696</td>\n",
       "      <td>[241.0, 7334.0, 3433.0, 7247.0, 1840.0, 5215.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHJ4X46OBBFQFQEGKO6CYQSL7A6Q</td>\n",
       "      <td>0441016995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1540233594357</td>\n",
       "      <td>13004</td>\n",
       "      <td>4750</td>\n",
       "      <td>[3132.0, 4886.0, 3905.0, 2187.0, 3951.0, 6240....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388843</th>\n",
       "      <td>AEEAI7QJ6HFCN43V543MOTKNBQOA</td>\n",
       "      <td>B0043M6L22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1528288422975</td>\n",
       "      <td>5335</td>\n",
       "      <td>7093</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4528.0, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388844</th>\n",
       "      <td>AGMWE3EQOAKN467EMLZFXS5FD7FQ</td>\n",
       "      <td>0525577947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1364849772000</td>\n",
       "      <td>1895</td>\n",
       "      <td>5383</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 5802.0, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388845</th>\n",
       "      <td>AGBD2QKG2VULRDA4OKNJZUII44JA</td>\n",
       "      <td>B00UXX5BAS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1313415114000</td>\n",
       "      <td>12423</td>\n",
       "      <td>4075</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 287...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388846</th>\n",
       "      <td>AGQ3G5TPEQV5AF4UPHKKCPK4C27Q</td>\n",
       "      <td>B00AEDDSZW</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1381858732000</td>\n",
       "      <td>10563</td>\n",
       "      <td>1139</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388847</th>\n",
       "      <td>AH5QXAX6DF5RDZVO77LNZTC5YYTQ</td>\n",
       "      <td>1501107968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1092489617000</td>\n",
       "      <td>9864</td>\n",
       "      <td>3024</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 170...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388848 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating      timestamp  \\\n",
       "0       AH377TAQBGVIUD75XIOSNRRBUMSA  B000OIZSLE     0.0  1603811722410   \n",
       "1       AGPAMWVXLFFWCBO3J4JNOYBB5CJQ  B01CXE9Q8C     4.0  1520074315327   \n",
       "2       AGSXDUEY3XZJVJSRBQCTAPOSY2NA  1451681755     0.0  1446855213000   \n",
       "3       AECGNMOCHNIEKROWI6NCZQE7QV3A  B001MSMULG     0.0  1412051625000   \n",
       "4       AHJ4X46OBBFQFQEGKO6CYQSL7A6Q  0441016995     0.0  1540233594357   \n",
       "...                              ...         ...     ...            ...   \n",
       "388843  AEEAI7QJ6HFCN43V543MOTKNBQOA  B0043M6L22     0.0  1528288422975   \n",
       "388844  AGMWE3EQOAKN467EMLZFXS5FD7FQ  0525577947     0.0  1364849772000   \n",
       "388845  AGBD2QKG2VULRDA4OKNJZUII44JA  B00UXX5BAS     0.0  1313415114000   \n",
       "388846  AGQ3G5TPEQV5AF4UPHKKCPK4C27Q  B00AEDDSZW     4.0  1381858732000   \n",
       "388847  AH5QXAX6DF5RDZVO77LNZTC5YYTQ  1501107968     0.0  1092489617000   \n",
       "\n",
       "        user_indice  item_indice  \\\n",
       "0              3520         5441   \n",
       "1              6133         2684   \n",
       "2             15471         3848   \n",
       "3              1717         4696   \n",
       "4             13004         4750   \n",
       "...             ...          ...   \n",
       "388843         5335         7093   \n",
       "388844         1895         5383   \n",
       "388845        12423         4075   \n",
       "388846        10563         1139   \n",
       "388847         9864         3024   \n",
       "\n",
       "                                            item_sequence  \n",
       "0       [-1.0, -1.0, -1.0, -1.0, 4238.0, 3266.0, 4316....  \n",
       "1       [-1.0, -1.0, -1.0, -1.0, -1.0, 2863.0, 5665.0,...  \n",
       "2       [-1.0, -1.0, -1.0, 2423.0, 5224.0, 6745.0, 360...  \n",
       "3       [241.0, 7334.0, 3433.0, 7247.0, 1840.0, 5215.0...  \n",
       "4       [3132.0, 4886.0, 3905.0, 2187.0, 3951.0, 6240....  \n",
       "...                                                   ...  \n",
       "388843  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4528.0, 5...  \n",
       "388844  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 5802.0, 6...  \n",
       "388845  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 287...  \n",
       "388846  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "388847  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 170...  \n",
       "\n",
       "[388848 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260fbe7-2f90-44a1-be74-ce5db9b511ee",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "240a04ed-8898-443f-b0f4-7399bfa63810",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset = UserItemRatingDFDataset(\n",
    "    train_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col\n",
    ")\n",
    "val_rating_dataset = UserItemRatingDFDataset(\n",
    "    val_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_rating_dataset, batch_size=args.batch_size, shuffle=False, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22dcf157-425f-4d15-9b53-e1ff93887def",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_items = len(item_indices)\n",
    "n_users = len(user_indices)\n",
    "\n",
    "model = init_model(n_users, n_items, args.embedding_dim, args.dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cbb2a8-a578-4ad2-941e-efd01d930336",
   "metadata": {},
   "source": [
    "#### Predict before train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26d95ffc-0aec-4239-aa33-d75dc2f40b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(7389, 128, padding_idx=7388)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.item_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0112de1e-1dce-4982-9663-a1df91fd0001",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>AFZTF5FPSVCDSGP26JOH4YEQNCEA</td>\n",
       "      <td>B00413QAAQ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1654453216826</td>\n",
       "      <td>14276</td>\n",
       "      <td>335</td>\n",
       "      <td>[-1, -1, 2325, 5456, 4211, 5519, 2377, 949, 62...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>AHLTOYNQMZTHCMH7CQOF7NMLOLZQ</td>\n",
       "      <td>0061537934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1653774386933</td>\n",
       "      <td>9613</td>\n",
       "      <td>6222</td>\n",
       "      <td>[3498, 6801, 4053, 6365, 2512, 4793, 230, 6366...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5929</th>\n",
       "      <td>AFTMTH6CJABHUGAIJIH63XQNHW6Q</td>\n",
       "      <td>B00GS8IRBC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1629825965677</td>\n",
       "      <td>18857</td>\n",
       "      <td>2127</td>\n",
       "      <td>[6966, 4566, 4896, 479, 5118, 1286, 1547, 856,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4363</th>\n",
       "      <td>AFBTAIIHMEFJ4HMM2SJME53EESXQ</td>\n",
       "      <td>B01FRSZAUO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1635228280407</td>\n",
       "      <td>12989</td>\n",
       "      <td>4943</td>\n",
       "      <td>[-1, -1, -1, 6282, 443, 5468, 112, 3338, 4193,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4471</th>\n",
       "      <td>AGJ6UBMA4ZOJBZC3YO7YLA3B4QSA</td>\n",
       "      <td>B07XSB35SS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1640356332345</td>\n",
       "      <td>17496</td>\n",
       "      <td>7211</td>\n",
       "      <td>[7324, 2138, 3112, 3028, 6484, 3912, 5240, 144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7018</th>\n",
       "      <td>AHUSHU2Q4CBYSCW4PVHJIQ2OMY2A</td>\n",
       "      <td>B075LK442Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1633619630976</td>\n",
       "      <td>14187</td>\n",
       "      <td>1686</td>\n",
       "      <td>[219, 2659, 7100, 5629, 4812, 1762, 5291, 244,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2812</th>\n",
       "      <td>AGKH2ABQSQB5IEM7E3BFF2PSTH2Q</td>\n",
       "      <td>B00FH1IBYE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1642118555178</td>\n",
       "      <td>12887</td>\n",
       "      <td>6229</td>\n",
       "      <td>[5033, 5638, 4391, 1475, 3200, 5680, 6289, 267...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>AECDOYKVV7RQUD5BVDQGSYPNGOVQ</td>\n",
       "      <td>B000T0G2DA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1647129480117</td>\n",
       "      <td>11515</td>\n",
       "      <td>3394</td>\n",
       "      <td>[2385, 3636, 3169, 3943, 3291, 2812, 1816, 14,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>AFVGJBPRCY3YGHTDUFXA6EIUNPGQ</td>\n",
       "      <td>B08KH8YT2S</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1629850034499</td>\n",
       "      <td>7451</td>\n",
       "      <td>506</td>\n",
       "      <td>[1777, 4131, 1788, 3629, 3889, 4528, 512, 2395...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>AGAW6UMSRL2JDTYR5VA4GMSRHU2A</td>\n",
       "      <td>B089GSGGRL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1657857178162</td>\n",
       "      <td>18194</td>\n",
       "      <td>6039</td>\n",
       "      <td>[5964, 2551, 1191, 3912, 3061, 1949, 1171, 370...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           user_id parent_asin  rating      timestamp  \\\n",
       "1786  AFZTF5FPSVCDSGP26JOH4YEQNCEA  B00413QAAQ     0.0  1654453216826   \n",
       "3980  AHLTOYNQMZTHCMH7CQOF7NMLOLZQ  0061537934     0.0  1653774386933   \n",
       "5929  AFTMTH6CJABHUGAIJIH63XQNHW6Q  B00GS8IRBC     0.0  1629825965677   \n",
       "4363  AFBTAIIHMEFJ4HMM2SJME53EESXQ  B01FRSZAUO     0.0  1635228280407   \n",
       "4471  AGJ6UBMA4ZOJBZC3YO7YLA3B4QSA  B07XSB35SS     0.0  1640356332345   \n",
       "7018  AHUSHU2Q4CBYSCW4PVHJIQ2OMY2A  B075LK442Z     1.0  1633619630976   \n",
       "2812  AGKH2ABQSQB5IEM7E3BFF2PSTH2Q  B00FH1IBYE     1.0  1642118555178   \n",
       "669   AECDOYKVV7RQUD5BVDQGSYPNGOVQ  B000T0G2DA     1.0  1647129480117   \n",
       "1796  AFVGJBPRCY3YGHTDUFXA6EIUNPGQ  B08KH8YT2S     1.0  1629850034499   \n",
       "3398  AGAW6UMSRL2JDTYR5VA4GMSRHU2A  B089GSGGRL     1.0  1657857178162   \n",
       "\n",
       "      user_indice  item_indice  \\\n",
       "1786        14276          335   \n",
       "3980         9613         6222   \n",
       "5929        18857         2127   \n",
       "4363        12989         4943   \n",
       "4471        17496         7211   \n",
       "7018        14187         1686   \n",
       "2812        12887         6229   \n",
       "669         11515         3394   \n",
       "1796         7451          506   \n",
       "3398        18194         6039   \n",
       "\n",
       "                                          item_sequence  \n",
       "1786  [-1, -1, 2325, 5456, 4211, 5519, 2377, 949, 62...  \n",
       "3980  [3498, 6801, 4053, 6365, 2512, 4793, 230, 6366...  \n",
       "5929  [6966, 4566, 4896, 479, 5118, 1286, 1547, 856,...  \n",
       "4363  [-1, -1, -1, 6282, 443, 5468, 112, 3338, 4193,...  \n",
       "4471  [7324, 2138, 3112, 3028, 6484, 3912, 5240, 144...  \n",
       "7018  [219, 2659, 7100, 5629, 4812, 1762, 5291, 244,...  \n",
       "2812  [5033, 5638, 4391, 1475, 3200, 5680, 6289, 267...  \n",
       "669   [2385, 3636, 3169, 3943, 3291, 2812, 1816, 14,...  \n",
       "1796  [1777, 4131, 1788, 3629, 3889, 4528, 512, 2395...  \n",
       "3398  [5964, 2551, 1191, 3912, 3061, 1949, 1171, 370...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = val_rating_dataset.df\n",
    "val_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9eb1583b-40f7-4157-a383-5891389ac119",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>AE6F6I77VA3ZOVOFHS3WEL5CXSJA</td>\n",
       "      <td>B00395ZYVS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1646616227324</td>\n",
       "      <td>11699</td>\n",
       "      <td>4579</td>\n",
       "      <td>[-1, -1, 7208, 3943, 4223, 6669, 585, 5870, 2671, 3193]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>AE6F6I77VA3ZOVOFHS3WEL5CXSJA</td>\n",
       "      <td>B08JKC299M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1646616227324</td>\n",
       "      <td>11699</td>\n",
       "      <td>6575</td>\n",
       "      <td>[-1, -1, 7208, 3943, 4223, 6669, 585, 5870, 2671, 3193]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           user_id parent_asin  rating      timestamp  \\\n",
       "2413  AE6F6I77VA3ZOVOFHS3WEL5CXSJA  B00395ZYVS     0.0  1646616227324   \n",
       "2676  AE6F6I77VA3ZOVOFHS3WEL5CXSJA  B08JKC299M     1.0  1646616227324   \n",
       "\n",
       "      user_indice  item_indice  \\\n",
       "2413        11699         4579   \n",
       "2676        11699         6575   \n",
       "\n",
       "                                                item_sequence  \n",
       "2413  [-1, -1, 7208, 3943, 4223, 6669, 585, 5870, 2671, 3193]  \n",
       "2676  [-1, -1, 7208, 3943, 4223, 6669, 585, 5870, 2671, 3193]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_id = val_df.sample(1)[args.user_col].values[0]\n",
    "# user_id = \"AH4AOFTTDPHPAFAAVFMAF25H2LIQ\"\n",
    "test_df = val_df.loc[lambda df: df[args.user_col].eq(user_id)]\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c48fbc80-eda8-4dff-a246-95f8f2f75082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-08 21:39:10.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mTest predicting before training with user_id = AE6F6I77VA3ZOVOFHS3WEL5CXSJA and parent_asin = B08JKC299M\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TwoTowerSequenceModel(\n",
       "  (item_embedding): Embedding(7389, 128, padding_idx=7388)\n",
       "  (user_embedding): Embedding(19734, 128)\n",
       "  (query_fc): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (candidate_fc): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_row = test_df.loc[lambda df: df[args.rating_col].gt(0)].iloc[0]\n",
    "item_id = test_row[args.item_col]\n",
    "item_sequence = test_row[\"item_sequence\"]\n",
    "logger.info(\n",
    "    f\"Test predicting before training with {args.user_col} = {user_id} and {args.item_col} = {item_id}\"\n",
    ")\n",
    "user_indice = idm.get_user_index(user_id)\n",
    "item_indice = idm.get_item_index(item_id)\n",
    "user = torch.tensor([user_indice])\n",
    "item_sequence = torch.tensor([item_sequence])\n",
    "item = torch.tensor([item_indice])\n",
    "\n",
    "model.eval()\n",
    "model.predict(user, item_sequence, item)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fd217c-c0c8-4e7c-81fe-6eb36f4729b5",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9daad4-1365-4e8e-8f73-80ca5513572b",
   "metadata": {},
   "source": [
    "##### Overfit 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a1cd9bd-e2c6-404b-b6ae-b26a7d35a0ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type                   | Params | Mode \n",
      "----------------------------------------------------------------------\n",
      "0 | model              | TwoTowerSequenceModel  | 3.5 M  | train\n",
      "1 | val_roc_auc_metric | BinaryAUROC            | 0      | train\n",
      "2 | val_pr_auc_metric  | BinaryAveragePrecision | 0      | train\n",
      "----------------------------------------------------------------------\n",
      "3.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.5 M     Total params\n",
      "14.087    Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ff63e7a9fb4f5aa4d933d740f6b1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                          | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:252: UserWarning:\n",
      "\n",
      "You requested to overfit but enabled val dataloader shuffling. We are turning off the val dataloader shuffling for you.\n",
      "\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: PossibleUserWarning:\n",
      "\n",
      "The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:252: UserWarning:\n",
      "\n",
      "You requested to overfit but enabled train dataloader shuffling. We are turning off the train dataloader shuffling for you.\n",
      "\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: PossibleUserWarning:\n",
      "\n",
      "The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:310: PossibleUserWarning:\n",
      "\n",
      "The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8524545dd9bc4c6981c717516b4cb955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                 | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd3c149b5754470b8f62874ccddc99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ec692166c545af953e2a0ef858207f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79845a1466654f529855fba131358b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f19d19269f41d59e7fd0c09e6872be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45444d5247534f10a4ad179dfc6d13c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e805b816e543adbc1fab8c71df392a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2198698aae964a4385ef33aebe17a533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e361aa1166e54df99275d7e1f10248f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968b5c2a1efb4f3cb26978b95d36cb6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17162f2d96af475a9f137dfaed232ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c555fdc3a3924fa6a40cb3621b300682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c9053950a74ebc909061fc84d6cebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29ddbaf29a5477fba7154aceff89671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85497648228b4132b664f36280bf75e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-08 21:39:11.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.sequence.trainer\u001b[0m:\u001b[36mon_fit_end\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mLogging classification metrics...\u001b[0m\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "\u001b[32m2025-03-08 21:39:27.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogs available at /home/dvq/frostmourne/recsys-blog/1-seq-model/notebooks/data/003-two-tower-sequence-modeling/logs/overfit/lightning_logs/version_1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_roc_auc\", patience=10, mode=\"max\", verbose=False\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, args.embedding_dim, dropout=0)\n",
    "lit_model = LitSequenceRatingPrediction(\n",
    "    model,\n",
    "    learning_rate=args.learning_rate,\n",
    "    l2_reg=0.0,\n",
    "    log_dir=args.notebook_persist_dp,\n",
    "    accelerator=args.device,\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persist_dp}/logs/overfit\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    max_epochs=100,\n",
    "    overfit_batches=1,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=train_loader,\n",
    ")\n",
    "logger.info(f\"Logs available at {trainer.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2cc9ae0-a993-4815-bebd-85cc51e68e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2075fe3a62ecfc83\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2075fe3a62ecfc83\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Need to make sure port 6006 at local is accessible\n",
    "%tensorboard --logdir $trainer.log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c7e4af-5c66-454e-9e2c-2ca134f4e1cf",
   "metadata": {},
   "source": [
    "##### Fit on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fef36c3-5263-4d91-8d7f-364d45c20719",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type                   | Params | Mode \n",
      "----------------------------------------------------------------------\n",
      "0 | model              | TwoTowerSequenceModel  | 3.5 M  | train\n",
      "1 | val_roc_auc_metric | BinaryAUROC            | 0      | train\n",
      "2 | val_pr_auc_metric  | BinaryAveragePrecision | 0      | train\n",
      "----------------------------------------------------------------------\n",
      "3.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.5 M     Total params\n",
      "14.087    Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67abbd246384fc58835a04f05ea04b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                          | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: PossibleUserWarning:\n",
      "\n",
      "The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: PossibleUserWarning:\n",
      "\n",
      "The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c82bb20b9554ac8b5ccfd821a8be24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                 | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e088134550844a5d85954a8cee343390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c82facc78d3b4f32a7a6465f6491e0e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabed5b1f59b40c3acbc7a54f7e7795d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7ba92b31f2403a864e88a5ce1df4e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb2e1dc1667493c9e6a2d804e0168d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681f232d112d4193a1bee46345bee167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56fee12e29f7489490551bdc0a4ee12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b957fd0889d45dcab3710a95bfee84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5824b0c6f44bf181740c587e0a59b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a727b762e147c7892703f5c68ad392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d49d0ca397b4988a39c0e7f34665902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75facd621f4a42c6a1a6199c3ac072a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-08 21:43:08.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.sequence.trainer\u001b[0m:\u001b[36mon_fit_end\u001b[0m:\u001b[36m165\u001b[0m - \u001b[1mLoading best model from /home/dvq/frostmourne/recsys-blog/1-seq-model/notebooks/data/003-two-tower-sequence-modeling/checkpoints/best-checkpoint.ckpt...\u001b[0m\n",
      "\u001b[32m2025-03-08 21:43:08.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.sequence.trainer\u001b[0m:\u001b[36mon_fit_end\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mLogging classification metrics...\u001b[0m\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "\u001b[32m2025-03-08 21:43:09.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.sequence.trainer\u001b[0m:\u001b[36mon_fit_end\u001b[0m:\u001b[36m175\u001b[0m - \u001b[1mLogging ranking metrics...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f914b3d173b4f1989238eb943521419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating recommendations:   0%|          | 0/434 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run 003-two-tower-sequence-modeling at: http://localhost:5002/#/experiments/3/runs/e71802367e2b45d0889b384c6243d00e\n",
      "🧪 View experiment at: http://localhost:5002/#/experiments/3\n"
     ]
    }
   ],
   "source": [
    "# papermill_description=fit-model\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_roc_auc\", patience=args.early_stopping_patience, mode=\"max\", verbose=False\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{args.notebook_persist_dp}/checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_roc_auc\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "model = init_model(\n",
    "    n_users,\n",
    "    n_items,\n",
    "    args.embedding_dim,\n",
    "    dropout=args.dropout\n",
    ")\n",
    "lit_model = LitSequenceRatingPrediction(\n",
    "    model,\n",
    "    learning_rate=args.learning_rate,\n",
    "    l2_reg=args.l2_reg,\n",
    "    log_dir=args.notebook_persist_dp,\n",
    "    evaluate_ranking=True,\n",
    "    idm=idm,\n",
    "    args=args,\n",
    "    accelerator=args.device,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persist_dp}/logs/run\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    max_epochs=args.max_epochs,\n",
    "    callbacks=[early_stopping, checkpoint_callback],\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    logger=args._mlf_logger if args.log_to_mlflow else None,\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af44bf35-e7c7-4718-97b8-238e89b7f3f0",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-08 21:43:14.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1mTest predicting after training with user_id = AE6F6I77VA3ZOVOFHS3WEL5CXSJA and parent_asin = B08JKC299M\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TwoTowerSequenceModel(\n",
       "  (item_embedding): Embedding(7389, 128, padding_idx=7388)\n",
       "  (user_embedding): Embedding(19734, 128)\n",
       "  (query_fc): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (candidate_fc): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info(\n",
    "    f\"Test predicting after training with {args.user_col} = {user_id} and {args.item_col} = {item_id}\"\n",
    ")\n",
    "model.eval()\n",
    "model = model.to(user.device)\n",
    "model.predict(user, item_sequence, item)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e1dd22-bcb9-4582-96d0-30acc4e8b790",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Load best checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "092427a8-ac4e-4752-a0ee-10729b6e563c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-08 21:43:14.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1mLoading best checkpoint from /home/dvq/frostmourne/recsys-blog/1-seq-model/notebooks/data/003-two-tower-sequence-modeling/checkpoints/best-checkpoint.ckpt...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Loading best checkpoint from {checkpoint_callback.best_model_path}...\")\n",
    "args.best_checkpoint_path = checkpoint_callback.best_model_path\n",
    "\n",
    "best_trainer = LitSequenceRatingPrediction.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    model=init_model(n_users, n_items, args.embedding_dim, dropout=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e68989e7-cd28-4cb3-9a28-5bd477bb67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = best_trainer.model.to(lit_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72062d94-6ee8-480f-b7c6-9dcae2ceeb8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5831], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.eval()\n",
    "best_model.predict(user, item_sequence, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26afc39d-5cbd-4ea4-9484-f6419b460bde",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Persist id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "275bcb81-bf50-4757-9e63-5c7a317b276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.log_to_mlflow:\n",
    "    # Persist id_mapping so that at inference we can predict based on item_ids (string) instead of item_index\n",
    "    run_id = trainer.logger.run_id\n",
    "    mlf_client = trainer.logger.experiment\n",
    "    mlf_client.log_artifact(run_id, idm_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a53735-cada-4b16-b6ec-b958e20d8093",
   "metadata": {},
   "source": [
    "### Wrap inference function and register best checkpoint as MLflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc1da4ca-1616-4f57-99fb-cb851c535a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferrer = SequenceRatingPredictionInferenceWrapper(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a21791a9-d5fc-4abe-bc3c-820aba9f0759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9204059], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_input = {\n",
    "    \"user_ids\": [idm.get_user_id(0)],\n",
    "    \"item_sequences\": [[idm.get_item_id(0), idm.get_item_id(1)]],\n",
    "    \"item_ids\": [idm.get_item_id(0)],\n",
    "}\n",
    "sample_output = inferrer.infer([0], [[0, 1]], [0])\n",
    "sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de2c043a-f777-4ade-ab80-cfa4d90aafa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/08 21:43:14 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6cef7c0c994278b4780370b28b3de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/08 21:43:16 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "Successfully registered model 'two_tower_sequence'.\n",
      "2025/03/08 21:43:17 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: two_tower_sequence, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run 003-two-tower-sequence-modeling at: http://localhost:5002/#/experiments/3/runs/e71802367e2b45d0889b384c6243d00e\n",
      "🧪 View experiment at: http://localhost:5002/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'two_tower_sequence'.\n"
     ]
    }
   ],
   "source": [
    "if args.log_to_mlflow:\n",
    "    run_id = trainer.logger.run_id\n",
    "    sample_output_np = sample_output\n",
    "    signature = infer_signature(sample_input, sample_output_np)\n",
    "    idm_filename = idm_fp.split(\"/\")[-1]\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        mlflow.pyfunc.log_model(\n",
    "            python_model=inferrer,\n",
    "            artifact_path=\"inferrer\",\n",
    "            # We log the id_mapping to the predict function so that it can accept item_id and automatically convert ot item_indice for PyTorch model to use\n",
    "            artifacts={\"idm\": mlflow.get_artifact_uri(idm_filename)},\n",
    "            signature=signature,\n",
    "            input_example=sample_input,\n",
    "            registered_model_name=args.mlf_model_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d5150-9851-4e61-b1af-8e619abc9ea4",
   "metadata": {},
   "source": [
    "# Set the newly trained model as champion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbf6428a-bc47-400a-99ac-666abfa4ce63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-08 21:43:17.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mThere is no champion alias for model two_tower_sequence\u001b[0m\n",
      "\u001b[32m2025-03-08 21:43:17.165\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mAliasing the new model as champion...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if args.log_to_mlflow:\n",
    "    # Get current champion\n",
    "    deploy_alias = \"champion\"\n",
    "    curr_model_run_id = None\n",
    "\n",
    "    min_roc_auc = args.min_roc_auc\n",
    "\n",
    "    try:\n",
    "        curr_champion_model = mlf_client.get_model_version_by_alias(\n",
    "            args.mlf_model_name, deploy_alias\n",
    "        )\n",
    "        curr_model_run_id = curr_champion_model.run_id\n",
    "    except MlflowException as e:\n",
    "        if \"not found\" in str(e).lower():\n",
    "            logger.info(\n",
    "                f\"There is no {deploy_alias} alias for model {args.mlf_model_name}\"\n",
    "            )\n",
    "\n",
    "    # Compare new vs curr models\n",
    "    new_mlf_run = trainer.logger.experiment.get_run(trainer.logger.run_id)\n",
    "    new_metrics = new_mlf_run.data.metrics\n",
    "    roc_auc = new_metrics[\"roc_auc\"]\n",
    "    if curr_model_run_id:\n",
    "        curr_model_run_info = mlf_client.get_run(curr_model_run_id)\n",
    "        curr_metrics = curr_model_run_info.data.metrics\n",
    "        if (curr_roc_auc := curr_metrics[\"roc_auc\"]) > min_roc_auc:\n",
    "            logger.info(\n",
    "                f\"Current {deploy_alias} model has {curr_roc_auc:,.4f} ROC-AUC. Setting it to the deploy baseline...\"\n",
    "            )\n",
    "            min_roc_auc = curr_roc_auc\n",
    "\n",
    "        top_metrics = [\"roc_auc\"]\n",
    "        vizer = ModelMetricsComparisonVisualizer(curr_metrics, new_metrics, top_metrics)\n",
    "        print(f\"Comparing metrics between new run and current champion:\")\n",
    "        display(vizer.compare_metrics_df())\n",
    "        vizer.create_metrics_comparison_plot(n_cols=5)\n",
    "        vizer.plot_diff()\n",
    "\n",
    "    # Register new champion\n",
    "    if roc_auc < min_roc_auc:\n",
    "        logger.info(\n",
    "            f\"Current run has ROC-AUC = {roc_auc:,.4f}, smaller than {min_roc_auc:,.4f}. Skip aliasing this model as the new {deploy_alias}..\"\n",
    "        )\n",
    "    else:\n",
    "        logger.info(f\"Aliasing the new model as champion...\")\n",
    "        # Get the model version for current run by assuming it's the most recent registered version\n",
    "        model_version = (\n",
    "            mlf_client.get_registered_model(args.mlf_model_name)\n",
    "            .latest_versions[0]\n",
    "            .version\n",
    "        )\n",
    "\n",
    "        mlf_client.set_registered_model_alias(\n",
    "            name=args.mlf_model_name, alias=\"champion\", version=model_version\n",
    "        )\n",
    "\n",
    "        mlf_client.set_model_version_tag(\n",
    "            name=args.mlf_model_name,\n",
    "            version=model_version,\n",
    "            key=\"author\",\n",
    "            value=args.author,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32096360-c26a-42de-9564-30634fb76eeb",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e98c6850-e4de-43fa-b132-0b97f138a0ed",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run 003-two-tower-sequence-modeling at: http://localhost:5002/#/experiments/3/runs/e71802367e2b45d0889b384c6243d00e\n",
      "🧪 View experiment at: http://localhost:5002/#/experiments/3\n"
     ]
    }
   ],
   "source": [
    "all_params = [args]\n",
    "\n",
    "if args.log_to_mlflow:\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        for params in all_params:\n",
    "            params_dict = params.model_dump()\n",
    "            params_ = dict()\n",
    "            for k, v in params_dict.items():\n",
    "                params_[f\"{params.__repr_name__()}.{k}\"] = v\n",
    "            mlflow.log_params(params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cff81a-484e-4919-be8f-0351cce91a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
