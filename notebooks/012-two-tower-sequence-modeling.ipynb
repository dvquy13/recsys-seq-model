{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bf1577c-6f3b-4b1c-a848-8f5e45ff8111",
   "metadata": {},
   "source": [
    "# Sequence modeling for ranking task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9309e017-0449-46ee-b7ca-4c4bcadeedf6",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8f6e8d-f776-4d39-898c-d783c5ae3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35b3499d-dc9c-405a-8714-a26341b581e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/mlflow/pyfunc/utils/data_validation.py:168: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from loguru import logger\n",
    "from mlflow.exceptions import MlflowException\n",
    "from mlflow.models.signature import infer_signature\n",
    "from pydantic import BaseModel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import mlflow\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.dataset import UserItemBinaryDFDataset as UserItemRatingDFDataset\n",
    "from src.id_mapper import IDMapper\n",
    "from src.sequence.inference import SequenceRatingPredictionInferenceWrapper\n",
    "from src.eval.compare_runs import ModelMetricsComparisonVisualizer\n",
    "from src.sequence.model import TwoTowerSequenceModel\n",
    "from src.sequence.trainer import LitSequenceRatingPrediction\n",
    "from src.sequence.utils import generate_item_sequences\n",
    "from src.viz import custom_style_plotly\n",
    "\n",
    "load_dotenv()\n",
    "custom_style_plotly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd804021-3424-48e0-973a-e662a72db544",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce522d9e-f35c-4cc5-a71e-68447956b31f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# This is a parameter cell used by papermill\n",
    "max_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea4e9a93-5b6a-4dec-97f0-b9aa3383c64d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-08 21:45:15.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36minit\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mSetting up MLflow experiment Retrieve - Binary - run 004-increase-lr...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"testing\": false,\n",
      "  \"author\": \"quy.dinh\",\n",
      "  \"log_to_mlflow\": true,\n",
      "  \"experiment_name\": \"Retrieve - Binary\",\n",
      "  \"run_name\": \"004-increase-lr\",\n",
      "  \"notebook_persist_dp\": \"/home/dvq/frostmourne/recsys-blog/1-seq-model/notebooks/data/004-increase-lr\",\n",
      "  \"random_seed\": 41,\n",
      "  \"device\": \"cuda\",\n",
      "  \"max_epochs\": 100,\n",
      "  \"batch_size\": 128,\n",
      "  \"user_col\": \"user_id\",\n",
      "  \"item_col\": \"parent_asin\",\n",
      "  \"rating_col\": \"rating\",\n",
      "  \"timestamp_col\": \"timestamp\",\n",
      "  \"top_k_retrieve\": 100,\n",
      "  \"top_k_rerank\": 10,\n",
      "  \"embedding_dim\": 128,\n",
      "  \"dropout\": 0.3,\n",
      "  \"early_stopping_patience\": 5,\n",
      "  \"learning_rate\": 0.003,\n",
      "  \"l2_reg\": 0.00001,\n",
      "  \"mlf_model_name\": \"two_tower_sequence\",\n",
      "  \"min_roc_auc\": 0.7,\n",
      "  \"best_checkpoint_path\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Args(BaseModel):\n",
    "    testing: bool = False\n",
    "    author: str = \"quy.dinh\"\n",
    "    log_to_mlflow: bool = True\n",
    "    experiment_name: str = \"Retrieve - Binary\"\n",
    "    run_name: str = \"004-increase-lr\"\n",
    "    notebook_persist_dp: str = None\n",
    "    random_seed: int = 41\n",
    "    device: str = None\n",
    "\n",
    "    max_epochs: int = max_epochs\n",
    "    batch_size: int = 128\n",
    "\n",
    "    user_col: str = \"user_id\"\n",
    "    item_col: str = \"parent_asin\"\n",
    "    rating_col: str = \"rating\"\n",
    "    timestamp_col: str = \"timestamp\"\n",
    "\n",
    "    top_k_retrieve: int = 100\n",
    "    top_k_rerank: int = 10\n",
    "\n",
    "    batch_size: int = 128\n",
    "\n",
    "    embedding_dim: int = 128\n",
    "    dropout: float = 0.3\n",
    "    early_stopping_patience: int = 5\n",
    "    learning_rate: float = 0.003\n",
    "    l2_reg: float = 1e-5\n",
    "\n",
    "    mlf_model_name: str = \"two_tower_sequence\"\n",
    "    min_roc_auc: float = 0.7\n",
    "\n",
    "    best_checkpoint_path: str = None\n",
    "\n",
    "    def init(self):\n",
    "        self.notebook_persist_dp = os.path.abspath(f\"data/{self.run_name}\")\n",
    "        os.makedirs(self.notebook_persist_dp, exist_ok=True)\n",
    "\n",
    "        if not (mlflow_uri := os.environ.get(\"MLFLOW_TRACKING_URI\")):\n",
    "            logger.warning(\n",
    "                \"Environment variable MLFLOW_TRACKING_URI is not set. Setting self.log_to_mlflow to false.\"\n",
    "            )\n",
    "            self.log_to_mlflow = False\n",
    "\n",
    "        if self.log_to_mlflow:\n",
    "            logger.info(\n",
    "                f\"Setting up MLflow experiment {self.experiment_name} - run {self.run_name}...\"\n",
    "            )\n",
    "            self._mlf_logger = MLFlowLogger(\n",
    "                experiment_name=self.experiment_name,\n",
    "                run_name=self.run_name,\n",
    "                tracking_uri=mlflow_uri,\n",
    "                log_model=True,\n",
    "            )\n",
    "\n",
    "        if self.device is None:\n",
    "            self.device = (\n",
    "                \"cuda\"\n",
    "                if torch.cuda.is_available()\n",
    "                else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "            )\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "args = Args().init()\n",
    "\n",
    "print(args.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acedcb-89e6-41c6-8969-bf3437fc7898",
   "metadata": {},
   "source": [
    "# Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a34cb5b-c7db-4b95-952b-5f4cb2e1a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(n_users, n_items, embedding_dim, dropout):\n",
    "    model = TwoTowerSequenceModel(\n",
    "        n_users, n_items, embedding_dim, dropout=dropout\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a71da-1ee3-474c-b3f4-4488d2a45dd3",
   "metadata": {},
   "source": [
    "# Test implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce5326d7-ec9d-422c-bbd8-03c837a23e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5279], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TwoTowerSequenceModel(\n",
       "  (item_embedding): Embedding(6, 8, padding_idx=5)\n",
       "  (user_embedding): Embedding(3, 8)\n",
       "  (query_fc): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (candidate_fc): Sequential(\n",
       "    (0): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 8\n",
    "batch_size = 2\n",
    "\n",
    "# Mock data\n",
    "user_indices = [0, 0, 1, 2, 2]\n",
    "item_indices = [0, 1, 2, 3, 4]\n",
    "timestamps = [0, 1, 2, 3, 4]\n",
    "ratings = [0, 4, 5, 3, 0]\n",
    "item_sequences = [\n",
    "    [-1, -1, 2, 3],\n",
    "    [-1, -1, 2, 3],\n",
    "    [-1, -1, 1, 3],\n",
    "    [-1, -1, 2, 1],\n",
    "    [-1, -1, 2, 1],\n",
    "]\n",
    "\n",
    "n_users = len(set(user_indices))\n",
    "n_items = len(set(item_indices))\n",
    "\n",
    "train_df = pd.DataFrame(\n",
    "    {\n",
    "        \"user_indice\": user_indices,\n",
    "        \"item_indice\": item_indices,\n",
    "        args.timestamp_col: timestamps,\n",
    "        args.rating_col: ratings,\n",
    "        \"item_sequence\": item_sequences,\n",
    "    }\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, embedding_dim, args.dropout)\n",
    "\n",
    "# Example forward pass\n",
    "model.eval()\n",
    "user = torch.tensor([0])\n",
    "item_sequence = torch.tensor([[-1, -1, -1, 0, 1]])\n",
    "target_item = torch.tensor([2])\n",
    "predictions = model.predict(user, item_sequence, target_item)\n",
    "print(predictions)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c0b1fea-0376-4624-ad8a-d000208a97f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rating_dataset = UserItemRatingDFDataset(\n",
    "    train_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=batch_size, shuffle=False, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e82d3d1-826a-409b-8440-46e0bd924269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': tensor([0, 0]), 'item': tensor([0, 1]), 'rating': tensor([0., 1.]), 'item_sequence': tensor([[-1, -1,  2,  3],\n",
      "        [-1, -1,  2,  3]]), 'item_sequence_ts_bucket': tensor([], size=(2, 0), dtype=torch.int64), 'item_feature': tensor([], size=(2, 0))}\n",
      "{'user': tensor([1, 2]), 'item': tensor([2, 3]), 'rating': tensor([1., 1.]), 'item_sequence': tensor([[-1, -1,  1,  3],\n",
      "        [-1, -1,  2,  1]]), 'item_sequence_ts_bucket': tensor([], size=(2, 0), dtype=torch.int64), 'item_feature': tensor([], size=(2, 0))}\n"
     ]
    }
   ],
   "source": [
    "for batch_input in train_loader:\n",
    "    print(batch_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02cb9ca4-11f1-45a8-911b-ed11c8391944",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 SUPER') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type                   | Params | Mode \n",
      "----------------------------------------------------------------------\n",
      "0 | model              | TwoTowerSequenceModel  | 312    | train\n",
      "1 | val_roc_auc_metric | BinaryAUROC            | 0      | train\n",
      "2 | val_pr_auc_metric  | BinaryAveragePrecision | 0      | train\n",
      "----------------------------------------------------------------------\n",
      "312       Trainable params\n",
      "0         Non-trainable params\n",
      "312       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8dd6c59adc14229918ec18756460ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                          | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f91cc322802433f808ed943f7040d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                 | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69835901ed8c4e8c84f9eba362a374ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b56d4dc27d415481d11c75cc960e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "\u001b[32m2025-03-08 21:45:15.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.sequence.trainer\u001b[0m:\u001b[36mon_fit_end\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mLogging classification metrics...\u001b[0m\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "lit_model = LitSequenceRatingPrediction(model, log_dir=args.notebook_persist_dp)\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=f\"{args.notebook_persist_dp}/test\",\n",
    "    max_epochs=2,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model, train_dataloaders=train_loader, val_dataloaders=train_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abf019c8-db28-4538-91e8-3904b8800e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5000, 0.6490, 0.6121, 0.5000], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "users = torch.tensor([0, 0, 0, 0])\n",
    "item_sequences = torch.tensor(\n",
    "    [[-1, -1, 2, 3], [-1, -1, 2, 3], [-1, -1, 1, 3], [-1, -1, 2, 1]]\n",
    ")\n",
    "items = torch.tensor([0, 1, 2, 3])\n",
    "predictions = model.predict(users, item_sequences, items)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f02734-1e63-4201-bd34-b3938ae50fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>predict</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>predict</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>predict</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>predict</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>predict</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_indice  item_indice  timestamp   source  \\\n",
       "0            0           -1          4  predict   \n",
       "1            0           -1          4  predict   \n",
       "2            1           -1          4  predict   \n",
       "3            2           -1          4  predict   \n",
       "4            2           -1          4  predict   \n",
       "\n",
       "                             item_sequence  \n",
       "0  [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1]  \n",
       "1  [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1]  \n",
       "2  [-1, -1, -1, -1, -1, -1, -1, -1, -1, 2]  \n",
       "3  [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3]  \n",
       "4  [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_predict_df(\n",
    "    train_df,\n",
    "    val_user_indices,\n",
    "    val_timestamp,\n",
    "    rating_col,\n",
    "    timestamp_col,\n",
    "    sequence_length=10,\n",
    "):\n",
    "    predict_df = pd.DataFrame(\n",
    "        {\n",
    "            \"user_indice\": val_user_indices,\n",
    "            \"item_indice\": -1,  # placeholder\n",
    "            \"timestamp\": val_timestamp,\n",
    "            \"source\": \"predict\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    predict_df = (\n",
    "        pd.concat(\n",
    "            [\n",
    "                train_df.loc[lambda df: df[rating_col].gt(0)][\n",
    "                    [\"user_indice\", \"item_indice\", timestamp_col]\n",
    "                ].assign(source=\"train\"),\n",
    "                predict_df,\n",
    "            ],\n",
    "            axis=0,\n",
    "        )\n",
    "        .pipe(\n",
    "            generate_item_sequences,\n",
    "            \"user_indice\",\n",
    "            \"item_indice\",\n",
    "            timestamp_col,\n",
    "            sequence_length=sequence_length,\n",
    "            padding=True,\n",
    "            padding_value=-1,\n",
    "        )\n",
    "        .loc[lambda df: df[\"source\"].eq(\"predict\")]\n",
    "        .assign(item_sequence=lambda df: df[\"item_sequence\"].apply(np.array))\n",
    "    )\n",
    "\n",
    "    return predict_df\n",
    "\n",
    "\n",
    "predict_df = create_predict_df(\n",
    "    train_df,\n",
    "    user_indices,\n",
    "    timestamps[-1],\n",
    "    args.rating_col,\n",
    "    args.timestamp_col,\n",
    "    sequence_length=10,\n",
    ")\n",
    "\n",
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50fdcf97-6271-406d-81b5-7e91a4c42dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_103618/349226613.py:3: UserWarning:\n",
      "\n",
      "Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc389f5638f4b8b9f36bec59046c0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating recommendations:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'user_indice': [0, 0, 0, 0, 1, 1, 2, 2, 2, 2],\n",
       " 'recommendation': [1, 5, 1, 5, 2, 3, 4, 3, 4, 3],\n",
       " 'score': [0.07410886883735657,\n",
       "  0.03674982860684395,\n",
       "  0.07410886883735657,\n",
       "  0.03674982860684395,\n",
       "  0.368076354265213,\n",
       "  0.20852333307266235,\n",
       "  1.3883150815963745,\n",
       "  1.0608761310577393,\n",
       "  1.3883150815963745,\n",
       "  1.0608762502670288]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations = model.recommend(\n",
    "    torch.tensor(predict_df[\"user_indice\"].values),\n",
    "    torch.tensor(predict_df[\"item_sequence\"].values.tolist()),\n",
    "    k=2,\n",
    "    batch_size=4,\n",
    ")\n",
    "recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170dec89-a874-4dce-8f94-07d978fcc5b8",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83803362-5eaa-40bb-b28b-878316d5db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"../data/train_features_neg_df.parquet\")\n",
    "val_df = pd.read_parquet(\"../data/val_features_neg_df.parquet\")\n",
    "idm_fp = \"../data/idm.json\"\n",
    "idm = IDMapper().load(idm_fp)\n",
    "\n",
    "assert (\n",
    "    train_df[args.user_col].map(lambda s: idm.get_user_index(s))\n",
    "    != train_df[\"user_indice\"]\n",
    ").sum() == 0, \"Mismatch IDM\"\n",
    "assert (\n",
    "    val_df[args.user_col].map(lambda s: idm.get_user_index(s)) != val_df[\"user_indice\"]\n",
    ").sum() == 0, \"Mismatch IDM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86f1e6e9-48ba-4f48-b693-ac028845938f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-08 21:45:16.205\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mlen(user_indices)=19,734, len(item_indices)=7,388\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "user_indices = train_df[\"user_indice\"].unique()\n",
    "item_indices = train_df[\"item_indice\"].unique()\n",
    "\n",
    "logger.info(f\"{len(user_indices)=:,.0f}, {len(item_indices)=:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a92a8ea7-928c-4656-b92c-2e137d78404a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AH377TAQBGVIUD75XIOSNRRBUMSA</td>\n",
       "      <td>B000OIZSLE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1603811722410</td>\n",
       "      <td>3520</td>\n",
       "      <td>5441</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, 4238.0, 3266.0, 4316....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGPAMWVXLFFWCBO3J4JNOYBB5CJQ</td>\n",
       "      <td>B01CXE9Q8C</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1520074315327</td>\n",
       "      <td>6133</td>\n",
       "      <td>2684</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, 2863.0, 5665.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGSXDUEY3XZJVJSRBQCTAPOSY2NA</td>\n",
       "      <td>1451681755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1446855213000</td>\n",
       "      <td>15471</td>\n",
       "      <td>3848</td>\n",
       "      <td>[-1.0, -1.0, -1.0, 2423.0, 5224.0, 6745.0, 360...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AECGNMOCHNIEKROWI6NCZQE7QV3A</td>\n",
       "      <td>B001MSMULG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1412051625000</td>\n",
       "      <td>1717</td>\n",
       "      <td>4696</td>\n",
       "      <td>[241.0, 7334.0, 3433.0, 7247.0, 1840.0, 5215.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHJ4X46OBBFQFQEGKO6CYQSL7A6Q</td>\n",
       "      <td>0441016995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1540233594357</td>\n",
       "      <td>13004</td>\n",
       "      <td>4750</td>\n",
       "      <td>[3132.0, 4886.0, 3905.0, 2187.0, 3951.0, 6240....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388843</th>\n",
       "      <td>AEEAI7QJ6HFCN43V543MOTKNBQOA</td>\n",
       "      <td>B0043M6L22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1528288422975</td>\n",
       "      <td>5335</td>\n",
       "      <td>7093</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4528.0, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388844</th>\n",
       "      <td>AGMWE3EQOAKN467EMLZFXS5FD7FQ</td>\n",
       "      <td>0525577947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1364849772000</td>\n",
       "      <td>1895</td>\n",
       "      <td>5383</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 5802.0, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388845</th>\n",
       "      <td>AGBD2QKG2VULRDA4OKNJZUII44JA</td>\n",
       "      <td>B00UXX5BAS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1313415114000</td>\n",
       "      <td>12423</td>\n",
       "      <td>4075</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 287...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388846</th>\n",
       "      <td>AGQ3G5TPEQV5AF4UPHKKCPK4C27Q</td>\n",
       "      <td>B00AEDDSZW</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1381858732000</td>\n",
       "      <td>10563</td>\n",
       "      <td>1139</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388847</th>\n",
       "      <td>AH5QXAX6DF5RDZVO77LNZTC5YYTQ</td>\n",
       "      <td>1501107968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1092489617000</td>\n",
       "      <td>9864</td>\n",
       "      <td>3024</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 170...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388848 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             user_id parent_asin  rating      timestamp  \\\n",
       "0       AH377TAQBGVIUD75XIOSNRRBUMSA  B000OIZSLE     0.0  1603811722410   \n",
       "1       AGPAMWVXLFFWCBO3J4JNOYBB5CJQ  B01CXE9Q8C     4.0  1520074315327   \n",
       "2       AGSXDUEY3XZJVJSRBQCTAPOSY2NA  1451681755     0.0  1446855213000   \n",
       "3       AECGNMOCHNIEKROWI6NCZQE7QV3A  B001MSMULG     0.0  1412051625000   \n",
       "4       AHJ4X46OBBFQFQEGKO6CYQSL7A6Q  0441016995     0.0  1540233594357   \n",
       "...                              ...         ...     ...            ...   \n",
       "388843  AEEAI7QJ6HFCN43V543MOTKNBQOA  B0043M6L22     0.0  1528288422975   \n",
       "388844  AGMWE3EQOAKN467EMLZFXS5FD7FQ  0525577947     0.0  1364849772000   \n",
       "388845  AGBD2QKG2VULRDA4OKNJZUII44JA  B00UXX5BAS     0.0  1313415114000   \n",
       "388846  AGQ3G5TPEQV5AF4UPHKKCPK4C27Q  B00AEDDSZW     4.0  1381858732000   \n",
       "388847  AH5QXAX6DF5RDZVO77LNZTC5YYTQ  1501107968     0.0  1092489617000   \n",
       "\n",
       "        user_indice  item_indice  \\\n",
       "0              3520         5441   \n",
       "1              6133         2684   \n",
       "2             15471         3848   \n",
       "3              1717         4696   \n",
       "4             13004         4750   \n",
       "...             ...          ...   \n",
       "388843         5335         7093   \n",
       "388844         1895         5383   \n",
       "388845        12423         4075   \n",
       "388846        10563         1139   \n",
       "388847         9864         3024   \n",
       "\n",
       "                                            item_sequence  \n",
       "0       [-1.0, -1.0, -1.0, -1.0, 4238.0, 3266.0, 4316....  \n",
       "1       [-1.0, -1.0, -1.0, -1.0, -1.0, 2863.0, 5665.0,...  \n",
       "2       [-1.0, -1.0, -1.0, 2423.0, 5224.0, 6745.0, 360...  \n",
       "3       [241.0, 7334.0, 3433.0, 7247.0, 1840.0, 5215.0...  \n",
       "4       [3132.0, 4886.0, 3905.0, 2187.0, 3951.0, 6240....  \n",
       "...                                                   ...  \n",
       "388843  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 4528.0, 5...  \n",
       "388844  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 5802.0, 6...  \n",
       "388845  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 287...  \n",
       "388846  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1....  \n",
       "388847  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 170...  \n",
       "\n",
       "[388848 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260fbe7-2f90-44a1-be74-ce5db9b511ee",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "240a04ed-8898-443f-b0f4-7399bfa63810",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dataset = UserItemRatingDFDataset(\n",
    "    train_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col\n",
    ")\n",
    "val_rating_dataset = UserItemRatingDFDataset(\n",
    "    val_df, \"user_indice\", \"item_indice\", args.rating_col, args.timestamp_col\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    rating_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_rating_dataset, batch_size=args.batch_size, shuffle=False, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22dcf157-425f-4d15-9b53-e1ff93887def",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_items = len(item_indices)\n",
    "n_users = len(user_indices)\n",
    "\n",
    "model = init_model(n_users, n_items, args.embedding_dim, args.dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cbb2a8-a578-4ad2-941e-efd01d930336",
   "metadata": {},
   "source": [
    "#### Predict before train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26d95ffc-0aec-4239-aa33-d75dc2f40b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(7389, 128, padding_idx=7388)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.item_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0112de1e-1dce-4982-9663-a1df91fd0001",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>AGJMFI2X7BIY4WXPW6T76SKYGCKQ</td>\n",
       "      <td>B01L1CEZ6K</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1630192892379</td>\n",
       "      <td>19523</td>\n",
       "      <td>4203</td>\n",
       "      <td>[2488, 4965, 3977, 6605, 6719, 81, 4288, 3005,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>AFWDH4AG6YDX4ZKQU6G5OGEMTAKQ</td>\n",
       "      <td>B093GWDR1L</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1635415157316</td>\n",
       "      <td>10189</td>\n",
       "      <td>1547</td>\n",
       "      <td>[689, 6063, 3224, 3468, 5500, 514, 3300, 853, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>AHDMMGUMXCZYRPU55JUTCKGLQAXA</td>\n",
       "      <td>B08HRQ44JJ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1632250575850</td>\n",
       "      <td>252</td>\n",
       "      <td>3773</td>\n",
       "      <td>[-1, -1, -1, 6642, 742, 591, 4203, 3152, 1932,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>AEK35YUNHPSEDPTN6ZVMBUHJQHAQ</td>\n",
       "      <td>B00O2BKKUS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1642552092831</td>\n",
       "      <td>14279</td>\n",
       "      <td>2506</td>\n",
       "      <td>[4005, 1679, 4913, 6527, 5884, 3388, 6328, 378...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5971</th>\n",
       "      <td>AH2LLXFZEGA7SDATMSXC7MEA3BAQ</td>\n",
       "      <td>0694003611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1639170230307</td>\n",
       "      <td>11382</td>\n",
       "      <td>4214</td>\n",
       "      <td>[2957, 7150, 1834, 5200, 6504, 6814, 4646, 246...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>AFN332ZERLJLNEVZIOJ2HIJRIUOA</td>\n",
       "      <td>B005HFHYM0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1647373040285</td>\n",
       "      <td>5035</td>\n",
       "      <td>6225</td>\n",
       "      <td>[759, 1707, 3455, 4433, 5440, 300, 656, 6904, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6361</th>\n",
       "      <td>AGRCLUWCIM7MUCYR3564H5XL5YQA</td>\n",
       "      <td>B07C1XRQVJ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1646279815251</td>\n",
       "      <td>12160</td>\n",
       "      <td>4723</td>\n",
       "      <td>[-1, -1, -1, 5269, 3468, 3808, 1641, 5025, 283...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5752</th>\n",
       "      <td>AFWGPM3OXOH5H4Z6F7M232LTHOEQ</td>\n",
       "      <td>B088DRJXHW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1642287628062</td>\n",
       "      <td>13084</td>\n",
       "      <td>3651</td>\n",
       "      <td>[2508, 3429, 7211, 230, 4392, 6752, 13, 2216, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>AGEQN3CZA5LEIEJFQ6ZVYNNAS7KQ</td>\n",
       "      <td>B01AGIBS1K</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1632554918152</td>\n",
       "      <td>328</td>\n",
       "      <td>6083</td>\n",
       "      <td>[2629, 7379, 6988, 2427, 1648, 6282, 3530, 229...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>AETKMELGAQOSEYYXZIX5YB2RB5BQ</td>\n",
       "      <td>B004SQSMV6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1632075470350</td>\n",
       "      <td>8760</td>\n",
       "      <td>7353</td>\n",
       "      <td>[-1, -1, -1, 1261, 1614, 4410, 6905, 1406, 596...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           user_id parent_asin  rating      timestamp  \\\n",
       "3849  AGJMFI2X7BIY4WXPW6T76SKYGCKQ  B01L1CEZ6K     0.0  1630192892379   \n",
       "1344  AFWDH4AG6YDX4ZKQU6G5OGEMTAKQ  B093GWDR1L     1.0  1635415157316   \n",
       "6063  AHDMMGUMXCZYRPU55JUTCKGLQAXA  B08HRQ44JJ     1.0  1632250575850   \n",
       "4851  AEK35YUNHPSEDPTN6ZVMBUHJQHAQ  B00O2BKKUS     1.0  1642552092831   \n",
       "5971  AH2LLXFZEGA7SDATMSXC7MEA3BAQ  0694003611     0.0  1639170230307   \n",
       "2589  AFN332ZERLJLNEVZIOJ2HIJRIUOA  B005HFHYM0     0.0  1647373040285   \n",
       "6361  AGRCLUWCIM7MUCYR3564H5XL5YQA  B07C1XRQVJ     1.0  1646279815251   \n",
       "5752  AFWGPM3OXOH5H4Z6F7M232LTHOEQ  B088DRJXHW     1.0  1642287628062   \n",
       "3488  AGEQN3CZA5LEIEJFQ6ZVYNNAS7KQ  B01AGIBS1K     1.0  1632554918152   \n",
       "2706  AETKMELGAQOSEYYXZIX5YB2RB5BQ  B004SQSMV6     0.0  1632075470350   \n",
       "\n",
       "      user_indice  item_indice  \\\n",
       "3849        19523         4203   \n",
       "1344        10189         1547   \n",
       "6063          252         3773   \n",
       "4851        14279         2506   \n",
       "5971        11382         4214   \n",
       "2589         5035         6225   \n",
       "6361        12160         4723   \n",
       "5752        13084         3651   \n",
       "3488          328         6083   \n",
       "2706         8760         7353   \n",
       "\n",
       "                                          item_sequence  \n",
       "3849  [2488, 4965, 3977, 6605, 6719, 81, 4288, 3005,...  \n",
       "1344  [689, 6063, 3224, 3468, 5500, 514, 3300, 853, ...  \n",
       "6063  [-1, -1, -1, 6642, 742, 591, 4203, 3152, 1932,...  \n",
       "4851  [4005, 1679, 4913, 6527, 5884, 3388, 6328, 378...  \n",
       "5971  [2957, 7150, 1834, 5200, 6504, 6814, 4646, 246...  \n",
       "2589  [759, 1707, 3455, 4433, 5440, 300, 656, 6904, ...  \n",
       "6361  [-1, -1, -1, 5269, 3468, 3808, 1641, 5025, 283...  \n",
       "5752  [2508, 3429, 7211, 230, 4392, 6752, 13, 2216, ...  \n",
       "3488  [2629, 7379, 6988, 2427, 1648, 6282, 3530, 229...  \n",
       "2706  [-1, -1, -1, 1261, 1614, 4410, 6905, 1406, 596...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = val_rating_dataset.df\n",
    "val_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9eb1583b-40f7-4157-a383-5891389ac119",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_indice</th>\n",
       "      <th>item_indice</th>\n",
       "      <th>item_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>AGPFDVQLGSSI5PSSEQDZJED3DYXQ</td>\n",
       "      <td>014241977X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1629241607695</td>\n",
       "      <td>8253</td>\n",
       "      <td>7168</td>\n",
       "      <td>[-1, -1, 3991, 5085, 39, 6672, 398, 2656, 1280, 5372]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>AGPFDVQLGSSI5PSSEQDZJED3DYXQ</td>\n",
       "      <td>150116077X</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1629241607695</td>\n",
       "      <td>8253</td>\n",
       "      <td>5200</td>\n",
       "      <td>[-1, -1, 3991, 5085, 39, 6672, 398, 2656, 1280, 5372]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           user_id parent_asin  rating      timestamp  \\\n",
       "2014  AGPFDVQLGSSI5PSSEQDZJED3DYXQ  014241977X     0.0  1629241607695   \n",
       "4454  AGPFDVQLGSSI5PSSEQDZJED3DYXQ  150116077X     1.0  1629241607695   \n",
       "\n",
       "      user_indice  item_indice  \\\n",
       "2014         8253         7168   \n",
       "4454         8253         5200   \n",
       "\n",
       "                                              item_sequence  \n",
       "2014  [-1, -1, 3991, 5085, 39, 6672, 398, 2656, 1280, 5372]  \n",
       "4454  [-1, -1, 3991, 5085, 39, 6672, 398, 2656, 1280, 5372]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_id = val_df.sample(1)[args.user_col].values[0]\n",
    "# user_id = \"AH4AOFTTDPHPAFAAVFMAF25H2LIQ\"\n",
    "test_df = val_df.loc[lambda df: df[args.user_col].eq(user_id)]\n",
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c48fbc80-eda8-4dff-a246-95f8f2f75082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-08 21:45:16.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mTest predicting before training with user_id = AGPFDVQLGSSI5PSSEQDZJED3DYXQ and parent_asin = 150116077X\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TwoTowerSequenceModel(\n",
       "  (item_embedding): Embedding(7389, 128, padding_idx=7388)\n",
       "  (user_embedding): Embedding(19734, 128)\n",
       "  (query_fc): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (candidate_fc): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_row = test_df.loc[lambda df: df[args.rating_col].gt(0)].iloc[0]\n",
    "item_id = test_row[args.item_col]\n",
    "item_sequence = test_row[\"item_sequence\"]\n",
    "logger.info(\n",
    "    f\"Test predicting before training with {args.user_col} = {user_id} and {args.item_col} = {item_id}\"\n",
    ")\n",
    "user_indice = idm.get_user_index(user_id)\n",
    "item_indice = idm.get_item_index(item_id)\n",
    "user = torch.tensor([user_indice])\n",
    "item_sequence = torch.tensor([item_sequence])\n",
    "item = torch.tensor([item_indice])\n",
    "\n",
    "model.eval()\n",
    "model.predict(user, item_sequence, item)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fd217c-c0c8-4e7c-81fe-6eb36f4729b5",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9daad4-1365-4e8e-8f73-80ca5513572b",
   "metadata": {},
   "source": [
    "##### Overfit 1 batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a1cd9bd-e2c6-404b-b6ae-b26a7d35a0ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(overfit_batches=1)` was configured so 1 batch will be used.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type                   | Params | Mode \n",
      "----------------------------------------------------------------------\n",
      "0 | model              | TwoTowerSequenceModel  | 3.5 M  | train\n",
      "1 | val_roc_auc_metric | BinaryAUROC            | 0      | train\n",
      "2 | val_pr_auc_metric  | BinaryAveragePrecision | 0      | train\n",
      "----------------------------------------------------------------------\n",
      "3.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.5 M     Total params\n",
      "14.087    Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4687cd0e8d04bd5aa2cb7accef4cce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                          | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:252: UserWarning:\n",
      "\n",
      "You requested to overfit but enabled val dataloader shuffling. We are turning off the val dataloader shuffling for you.\n",
      "\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: PossibleUserWarning:\n",
      "\n",
      "The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:252: UserWarning:\n",
      "\n",
      "You requested to overfit but enabled train dataloader shuffling. We are turning off the train dataloader shuffling for you.\n",
      "\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: PossibleUserWarning:\n",
      "\n",
      "The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:310: PossibleUserWarning:\n",
      "\n",
      "The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf41b97101f8401d9aea0ca97df308b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                 | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7c0600b6e74b9d96d1d3dd473d63dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709bc7aafd884d9ebf2e2e958ee526f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c0513b3db64ff6801176a5b28c0995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796adf237a4c40f8979dd7a9c30a2166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1deb01bf023f4ee684936c1b85c0cc4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbe3c2bda604076baecaff698457de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1dddbe308348bab756b76b805bb92e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc653ad55feb4adaae0928694ee368e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8081dbdc20842cca6993324ed9d8656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d655b58aa0475d8cacf166742a4068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3720096441934caea5f2550917d786a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dcdf29488864072b2349daf2f537c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-08 21:45:17.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.sequence.trainer\u001b[0m:\u001b[36mon_fit_end\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mLogging classification metrics...\u001b[0m\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "\u001b[32m2025-03-08 21:45:33.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogs available at /home/dvq/frostmourne/recsys-blog/1-seq-model/notebooks/data/004-increase-lr/logs/overfit/lightning_logs/version_0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_roc_auc\", patience=10, mode=\"max\", verbose=False\n",
    ")\n",
    "\n",
    "model = init_model(n_users, n_items, args.embedding_dim, dropout=0)\n",
    "lit_model = LitSequenceRatingPrediction(\n",
    "    model,\n",
    "    learning_rate=args.learning_rate,\n",
    "    l2_reg=0.0,\n",
    "    log_dir=args.notebook_persist_dp,\n",
    "    accelerator=args.device,\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persist_dp}/logs/overfit\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    max_epochs=100,\n",
    "    overfit_batches=1,\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=train_loader,\n",
    ")\n",
    "logger.info(f\"Logs available at {trainer.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2cc9ae0-a993-4815-bebd-85cc51e68e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9311fd2711560f40\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9311fd2711560f40\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Need to make sure port 6006 at local is accessible\n",
    "%tensorboard --logdir $trainer.log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c7e4af-5c66-454e-9e2c-2ca134f4e1cf",
   "metadata": {},
   "source": [
    "##### Fit on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef36c3-5263-4d91-8d7f-364d45c20719",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name               | Type                   | Params | Mode \n",
      "----------------------------------------------------------------------\n",
      "0 | model              | TwoTowerSequenceModel  | 3.5 M  | train\n",
      "1 | val_roc_auc_metric | BinaryAUROC            | 0      | train\n",
      "2 | val_pr_auc_metric  | BinaryAveragePrecision | 0      | train\n",
      "----------------------------------------------------------------------\n",
      "3.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.5 M     Total params\n",
      "14.087    Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451d15110eff4eaaa891efb083835cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                          | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: PossibleUserWarning:\n",
      "\n",
      "The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\n",
      "/home/dvq/frostmourne/recsys-blog/1-seq-model/.venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: PossibleUserWarning:\n",
      "\n",
      "The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba67829e1bd84e75ba67091c7e15bd62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                 | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb86f7947c7043b4917b368715d57c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80a5869b7ea49cf90d2a0bf7fa14012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8b3f7c54714bd6b5b87f165e72995e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ab174a80ce482da4afb4d0bbebff7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54743cb7074047c98ff612aa5bb20249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77d5ee0feeb4c659f5b0658e7cacf79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352c90fdd93743f4bc2e7f71c41ba798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d00f8004b9f420cab3b5e40b74a902e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98bd990cc7fb430ba05ffd03a4e9246e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8941d7fef7b34a7f8ea376d9b9edae16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ed40088f474bfab25de0e5e4b2dfa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                               | 0/? [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# papermill_description=fit-model\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_roc_auc\", patience=args.early_stopping_patience, mode=\"max\", verbose=False\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=f\"{args.notebook_persist_dp}/checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_roc_auc\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "model = init_model(\n",
    "    n_users,\n",
    "    n_items,\n",
    "    args.embedding_dim,\n",
    "    dropout=args.dropout\n",
    ")\n",
    "lit_model = LitSequenceRatingPrediction(\n",
    "    model,\n",
    "    learning_rate=args.learning_rate,\n",
    "    l2_reg=args.l2_reg,\n",
    "    log_dir=args.notebook_persist_dp,\n",
    "    evaluate_ranking=True,\n",
    "    idm=idm,\n",
    "    args=args,\n",
    "    accelerator=args.device,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    ")\n",
    "\n",
    "log_dir = f\"{args.notebook_persist_dp}/logs/run\"\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(\n",
    "    default_root_dir=log_dir,\n",
    "    max_epochs=args.max_epochs,\n",
    "    callbacks=[early_stopping, checkpoint_callback],\n",
    "    accelerator=args.device if args.device else \"auto\",\n",
    "    logger=args._mlf_logger if args.log_to_mlflow else None,\n",
    ")\n",
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af44bf35-e7c7-4718-97b8-238e89b7f3f0",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger.info(\n",
    "    f\"Test predicting after training with {args.user_col} = {user_id} and {args.item_col} = {item_id}\"\n",
    ")\n",
    "model.eval()\n",
    "model = model.to(user.device)\n",
    "model.predict(user, item_sequence, item)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e1dd22-bcb9-4582-96d0-30acc4e8b790",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Load best checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092427a8-ac4e-4752-a0ee-10729b6e563c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.info(f\"Loading best checkpoint from {checkpoint_callback.best_model_path}...\")\n",
    "args.best_checkpoint_path = checkpoint_callback.best_model_path\n",
    "\n",
    "best_trainer = LitSequenceRatingPrediction.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    model=init_model(n_users, n_items, args.embedding_dim, dropout=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68989e7-cd28-4cb3-9a28-5bd477bb67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = best_trainer.model.to(lit_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72062d94-6ee8-480f-b7c6-9dcae2ceeb8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "best_model.predict(user, item_sequence, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26afc39d-5cbd-4ea4-9484-f6419b460bde",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Persist id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275bcb81-bf50-4757-9e63-5c7a317b276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.log_to_mlflow:\n",
    "    # Persist id_mapping so that at inference we can predict based on item_ids (string) instead of item_index\n",
    "    run_id = trainer.logger.run_id\n",
    "    mlf_client = trainer.logger.experiment\n",
    "    mlf_client.log_artifact(run_id, idm_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a53735-cada-4b16-b6ec-b958e20d8093",
   "metadata": {},
   "source": [
    "### Wrap inference function and register best checkpoint as MLflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1da4ca-1616-4f57-99fb-cb851c535a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferrer = SequenceRatingPredictionInferenceWrapper(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21791a9-d5fc-4abe-bc3c-820aba9f0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = {\n",
    "    \"user_ids\": [idm.get_user_id(0)],\n",
    "    \"item_sequences\": [[idm.get_item_id(0), idm.get_item_id(1)]],\n",
    "    \"item_ids\": [idm.get_item_id(0)],\n",
    "}\n",
    "sample_output = inferrer.infer([0], [[0, 1]], [0])\n",
    "sample_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c043a-f777-4ade-ab80-cfa4d90aafa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args.log_to_mlflow:\n",
    "    run_id = trainer.logger.run_id\n",
    "    sample_output_np = sample_output\n",
    "    signature = infer_signature(sample_input, sample_output_np)\n",
    "    idm_filename = idm_fp.split(\"/\")[-1]\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        mlflow.pyfunc.log_model(\n",
    "            python_model=inferrer,\n",
    "            artifact_path=\"inferrer\",\n",
    "            # We log the id_mapping to the predict function so that it can accept item_id and automatically convert ot item_indice for PyTorch model to use\n",
    "            artifacts={\"idm\": mlflow.get_artifact_uri(idm_filename)},\n",
    "            signature=signature,\n",
    "            input_example=sample_input,\n",
    "            registered_model_name=args.mlf_model_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95d5150-9851-4e61-b1af-8e619abc9ea4",
   "metadata": {},
   "source": [
    "# Set the newly trained model as champion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf6428a-bc47-400a-99ac-666abfa4ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.log_to_mlflow:\n",
    "    # Get current champion\n",
    "    deploy_alias = \"champion\"\n",
    "    curr_model_run_id = None\n",
    "\n",
    "    min_roc_auc = args.min_roc_auc\n",
    "\n",
    "    try:\n",
    "        curr_champion_model = mlf_client.get_model_version_by_alias(\n",
    "            args.mlf_model_name, deploy_alias\n",
    "        )\n",
    "        curr_model_run_id = curr_champion_model.run_id\n",
    "    except MlflowException as e:\n",
    "        if \"not found\" in str(e).lower():\n",
    "            logger.info(\n",
    "                f\"There is no {deploy_alias} alias for model {args.mlf_model_name}\"\n",
    "            )\n",
    "\n",
    "    # Compare new vs curr models\n",
    "    new_mlf_run = trainer.logger.experiment.get_run(trainer.logger.run_id)\n",
    "    new_metrics = new_mlf_run.data.metrics\n",
    "    roc_auc = new_metrics[\"roc_auc\"]\n",
    "    if curr_model_run_id:\n",
    "        curr_model_run_info = mlf_client.get_run(curr_model_run_id)\n",
    "        curr_metrics = curr_model_run_info.data.metrics\n",
    "        if (curr_roc_auc := curr_metrics[\"roc_auc\"]) > min_roc_auc:\n",
    "            logger.info(\n",
    "                f\"Current {deploy_alias} model has {curr_roc_auc:,.4f} ROC-AUC. Setting it to the deploy baseline...\"\n",
    "            )\n",
    "            min_roc_auc = curr_roc_auc\n",
    "\n",
    "        top_metrics = [\"roc_auc\"]\n",
    "        vizer = ModelMetricsComparisonVisualizer(curr_metrics, new_metrics, top_metrics)\n",
    "        print(f\"Comparing metrics between new run and current champion:\")\n",
    "        display(vizer.compare_metrics_df())\n",
    "        vizer.create_metrics_comparison_plot(n_cols=5)\n",
    "        vizer.plot_diff()\n",
    "\n",
    "    # Register new champion\n",
    "    if roc_auc < min_roc_auc:\n",
    "        logger.info(\n",
    "            f\"Current run has ROC-AUC = {roc_auc:,.4f}, smaller than {min_roc_auc:,.4f}. Skip aliasing this model as the new {deploy_alias}..\"\n",
    "        )\n",
    "    else:\n",
    "        logger.info(f\"Aliasing the new model as champion...\")\n",
    "        # Get the model version for current run by assuming it's the most recent registered version\n",
    "        model_version = (\n",
    "            mlf_client.get_registered_model(args.mlf_model_name)\n",
    "            .latest_versions[0]\n",
    "            .version\n",
    "        )\n",
    "\n",
    "        mlf_client.set_registered_model_alias(\n",
    "            name=args.mlf_model_name, alias=\"champion\", version=model_version\n",
    "        )\n",
    "\n",
    "        mlf_client.set_model_version_tag(\n",
    "            name=args.mlf_model_name,\n",
    "            version=model_version,\n",
    "            key=\"author\",\n",
    "            value=args.author,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32096360-c26a-42de-9564-30634fb76eeb",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c6850-e4de-43fa-b132-0b97f138a0ed",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_params = [args]\n",
    "\n",
    "if args.log_to_mlflow:\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        for params in all_params:\n",
    "            params_dict = params.model_dump()\n",
    "            params_ = dict()\n",
    "            for k, v in params_dict.items():\n",
    "                params_[f\"{params.__repr_name__()}.{k}\"] = v\n",
    "            mlflow.log_params(params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cff81a-484e-4919-be8f-0351cce91a75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
